<!DOCTYPE html>
<html
  lang="en"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          Killer - CKA Simulator Kubernetes 1.29 - Big Wilte Cat&#39;s Home
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="大白猫" />
  <meta name="description" content="From: https://killer.sh Most of this page is direct copy, and I just added My Answer or Ref. Pre Setup Once you&amp;rsquo;ve gained access to your terminal it might be wise to spend ~1 minute to setup your environment. You could set these: alias k=kubectl # will already be pre-configured export do=&amp;#34;--dry-run=client -o yaml&amp;#34; # k create deploy nginx --image=nginx $do export now=&amp;#34;--force --grace-period 0&amp;#34; # k delete pod x $now" />

  <meta name="keywords" content="Hugo, theme, jane" />






<meta name="generator" content="Hugo 0.116.1" />


<link rel="canonical" href="https://zyt153.github.io/post/killer_practice/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="Killer - CKA Simulator Kubernetes 1.29" />
<meta property="og:description" content="From: https://killer.sh Most of this page is direct copy, and I just added My Answer or Ref. Pre Setup Once you&rsquo;ve gained access to your terminal it might be wise to spend ~1 minute to setup your environment. You could set these: alias k=kubectl # will already be pre-configured export do=&#34;--dry-run=client -o yaml&#34; # k create deploy nginx --image=nginx $do export now=&#34;--force --grace-period 0&#34; # k delete pod x $now" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zyt153.github.io/post/killer_practice/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-03-06T10:32:36+08:00" />
<meta property="article:modified_time" content="2024-03-06T10:32:36+08:00" />
<meta itemprop="name" content="Killer - CKA Simulator Kubernetes 1.29">
<meta itemprop="description" content="From: https://killer.sh Most of this page is direct copy, and I just added My Answer or Ref. Pre Setup Once you&rsquo;ve gained access to your terminal it might be wise to spend ~1 minute to setup your environment. You could set these: alias k=kubectl # will already be pre-configured export do=&#34;--dry-run=client -o yaml&#34; # k create deploy nginx --image=nginx $do export now=&#34;--force --grace-period 0&#34; # k delete pod x $now"><meta itemprop="datePublished" content="2024-03-06T10:32:36+08:00" />
<meta itemprop="dateModified" content="2024-03-06T10:32:36+08:00" />
<meta itemprop="wordCount" content="14342">
<meta itemprop="keywords" content="k8s,cka," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Killer - CKA Simulator Kubernetes 1.29"/>
<meta name="twitter:description" content="From: https://killer.sh Most of this page is direct copy, and I just added My Answer or Ref. Pre Setup Once you&rsquo;ve gained access to your terminal it might be wise to spend ~1 minute to setup your environment. You could set these: alias k=kubectl # will already be pre-configured export do=&#34;--dry-run=client -o yaml&#34; # k create deploy nginx --image=nginx $do export now=&#34;--force --grace-period 0&#34; # k delete pod x $now"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Hey!</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/">Home</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/post/">Archives</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/tags/">Tags</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/categories/">Categories</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/about/">About</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/">Find More</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      Hey!
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/">Home</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/post/">Archives</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/tags/">Tags</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/categories/">Categories</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/about/">About</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://zyt153.github.io/">Find More</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">Killer - CKA Simulator Kubernetes 1.29</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      <a href="/about">
        <span class="post-meta-author-name">
          大白猫
        </span>
      </a>
    
  </div>

  <div class="post-meta-time">
    <time datetime="2024-03-06">
      2024-03-06
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        14342 words -
        29 min read
      </span>

    <div class="post-meta-category">
        <a href="https://zyt153.github.io/categories/k8s/"> k8s </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <p>From: <a href="https://killer.sh/">https://killer.sh</a></p>
<p>Most of this page is direct copy, and I just added <em>My Answer</em> or <em>Ref</em>.</p>
<h2 id="pre-setup">Pre Setup</h2>
<p>Once you&rsquo;ve gained access to your terminal it might be wise to spend ~1 minute to setup your environment. You could set these:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>alias k<span style="color:#f92672">=</span>kubectl                         <span style="color:#75715e"># will already be pre-configured</span>
</span></span><span style="display:flex;"><span>export <span style="color:#66d9ef">do</span><span style="color:#f92672">=</span><span style="color:#e6db74">&#34;--dry-run=client -o yaml&#34;</span>    <span style="color:#75715e"># k create deploy nginx --image=nginx $do</span>
</span></span><span style="display:flex;"><span>export now<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;--force --grace-period 0&#34;</span>   <span style="color:#75715e"># k delete pod x $now</span>
</span></span></code></pre></div><p><strong>Vim</strong></p>
<p>The following settings will already be configured in your real exam environment in <code>~/.vimrc</code>. But it can never hurt to be able to type these down:</p>
<pre tabindex="0"><code>set tabstop=2
set expandtab
set shiftwidth=2
</code></pre><p>More setup suggestions are in the <strong>tips section</strong>.</p>
<h2 id="question-1--contexts">Question 1 | Contexts</h2>
<h3 id="question">Question</h3>
<p>You have access to multiple clusters from your main terminal through <code>kubectl</code> contexts. Write all those context names into <code>/opt/course/1/contexts</code>.</p>
<p>Next write a command to display the current context into <code>/opt/course/1/context_default_kubectl.sh</code>, the command should use <code>kubectl</code>.</p>
<p>Finally write a second command doing the same thing into <code>/opt/course/1/context_default_no_kubectl.sh</code>, but without the use of <code>kubectl</code>.</p>
<h3 id="my-answer">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kc config get-contexts  <span style="color:#75715e"># manual copy</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;context-name&#34;</span> &gt; /opt/course/1/contexts
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vi /opt/course/1/context_default_kubectl.sh
</span></span><span style="display:flex;"><span>kubectl config current-context  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vi /opt/course/1/context_default_no_kubectl.sh
</span></span><span style="display:flex;"><span>cat ~/.kube/config | grep current  <span style="color:#75715e"># add</span>
</span></span></code></pre></div><h3 id="answer">Answer</h3>
<p>Maybe the fastest way is just to run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k config get-contexts <span style="color:#75715e"># copy manually</span>
</span></span><span style="display:flex;"><span>k config get-contexts -o name &gt; /opt/course/1/contexts
</span></span></code></pre></div><p>Or using jsonpath:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k config view -o yaml <span style="color:#75715e"># overview</span>
</span></span><span style="display:flex;"><span>k config view -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.contexts[*].name}&#34;</span>
</span></span><span style="display:flex;"><span>k config view -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.contexts[*].name}&#34;</span> | tr <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#e6db74">&#34;\n&#34;</span> <span style="color:#75715e"># new lines</span>
</span></span><span style="display:flex;"><span>k config view -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.contexts[*].name}&#34;</span> | tr <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#e6db74">&#34;\n&#34;</span> &gt; /opt/course/1/contexts 
</span></span></code></pre></div><p>The content should then look like:</p>
<pre tabindex="0"><code># /opt/course/1/contexts
k8s-c1-H
k8s-c2-AC
k8s-c3-CCC
</code></pre><p>Next create the first command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/1/context_default_kubectl.sh</span>
</span></span><span style="display:flex;"><span>kubectl config current-context
</span></span><span style="display:flex;"><span>➜ sh /opt/course/1/context_default_kubectl.sh
</span></span><span style="display:flex;"><span>k8s-c1-H
</span></span></code></pre></div><p>And the second one:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/1/context_default_no_kubectl.sh</span>
</span></span><span style="display:flex;"><span>cat ~/.kube/config | grep current
</span></span><span style="display:flex;"><span>➜ sh /opt/course/1/context_default_no_kubectl.sh
</span></span><span style="display:flex;"><span>current-context: k8s-c1-H
</span></span></code></pre></div><p>In the real exam you might need to filter and find information from bigger lists of resources, hence knowing a little jsonpath and simple bash filtering will be helpful.</p>
<p>The second command could also be improved to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/1/context_default_no_kubectl.sh</span>
</span></span><span style="display:flex;"><span>cat ~/.kube/config | grep current | sed -e <span style="color:#e6db74">&#34;s/current-context: //&#34;</span> 
</span></span></code></pre></div><h2 id="question-2--schedule-pod-on-controlplane-nodes">Question 2 | Schedule Pod on Controlplane Nodes</h2>
<h3 id="question-1">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Create a single <em>Pod</em> of image <code>httpd:2.4.41-alpine</code> in <em>Namespace</em> <code>default</code>. The <em>Pod</em> should be named <code>pod1</code> and the container should be named <code>pod1-container</code>. This <em>Pod</em> should <strong>only</strong> be scheduled on controlplane nodes. Do not add new labels to any nodes.</p>
<h3 id="my-answer-1">My Answer</h3>
<p>Create pod with this yaml but find pod is not running.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pod1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pod1-container </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:2.4.41-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/hostname</span>: <span style="color:#ae81ff">cluster1-controlplane1</span>
</span></span></code></pre></div><p>Then add tolerations by <code>kubectl edit</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>  <span style="color:#f92672">tolerations</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">effect</span>: <span style="color:#ae81ff">NoSchedule</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">key</span>: <span style="color:#ae81ff">node-role.kubernetes.io/control-plane</span>
</span></span></code></pre></div><h3 id="answer-1">Answer</h3>
<p>First we find the controlplane node(s) and their taints:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k get node <span style="color:#75715e"># find controlplane node</span>
</span></span><span style="display:flex;"><span>k describe node cluster1-controlplane1 | grep Taint -A1 <span style="color:#75715e"># get controlplane node taints</span>
</span></span><span style="display:flex;"><span>k get node cluster1-controlplane1 --show-labels <span style="color:#75715e"># get controlplane node labels</span>
</span></span></code></pre></div><p>Next we create the <em>Pod</em> template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># check the export on the very top of this document so we can use $do</span>
</span></span><span style="display:flex;"><span>k run pod1 --image<span style="color:#f92672">=</span>httpd:2.4.41-alpine $do &gt; 2.yaml
</span></span><span style="display:flex;"><span>vim 2.yaml
</span></span></code></pre></div><p>Perform the necessary changes manually. Use the Kubernetes docs and search for example for tolerations and nodeSelector to find examples:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 2.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">pod1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pod1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:2.4.41-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pod1-container                      </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tolerations</span>:                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">effect</span>: <span style="color:#ae81ff">NoSchedule                        </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">key</span>: <span style="color:#ae81ff">node-role.kubernetes.io/control-plane</span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeSelector</span>:                                <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">node-role.kubernetes.io/control-plane</span>: <span style="color:#e6db74">&#34;&#34;</span>  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>Important here to add the toleration for running on controlplane nodes, but also the nodeSelector to make sure it only runs on controlplane nodes. If we only specify a toleration the <em>Pod</em> can be scheduled on controlplane or worker nodes.</p>
<p>Now we create it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 2.yaml create
</span></span></code></pre></div><p>Let&rsquo;s check if the pod is scheduled:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod pod1 -o wide
</span></span><span style="display:flex;"><span>NAME   READY   STATUS    RESTARTS   ...    NODE                     NOMINATED NODE
</span></span><span style="display:flex;"><span>pod1   1/1     Running   <span style="color:#ae81ff">0</span>          ...    cluster1-controlplane1   &lt;none&gt;        
</span></span></code></pre></div><h2 id="question-3--scale-down-statefulset">Question 3 | Scale down StatefulSet</h2>
<h3 id="question-2">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>There are two <em>Pods</em> named <code>o3db-*</code> in <em>Namespace</em> <code>project-c13</code>. C13 management asked you to scale the <em>Pods</em> down to one replica to save resources.</p>
<h3 id="my-answer-2">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kc get pod -n project-c13
</span></span><span style="display:flex;"><span>kc delete pod o3db-0 <span style="color:#75715e"># try to delete but fail</span>
</span></span><span style="display:flex;"><span>kc describe pod o3db-0 <span style="color:#75715e"># find it is created by statefulset</span>
</span></span><span style="display:flex;"><span>kc get statefulset -n project-c13
</span></span><span style="display:flex;"><span>kc scale statefulset o3db -n project-c13 --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><h3 id="answer-2">Answer</h3>
<p>If we check the <em>Pods</em> we see two replicas:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 get pod | grep o3db
</span></span><span style="display:flex;"><span>o3db-0                                  1/1     Running   <span style="color:#ae81ff">0</span>          52s
</span></span><span style="display:flex;"><span>o3db-1                                  1/1     Running   <span style="color:#ae81ff">0</span>          42s
</span></span></code></pre></div><p>From their name it looks like these are managed by a <em>StatefulSet</em>. But if we&rsquo;re not sure we could also check for the most common resources which manage <em>Pods</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 get deploy,ds,sts | grep o3db
</span></span><span style="display:flex;"><span>statefulset.apps/o3db   2/2     2m56s
</span></span></code></pre></div><p>Confirmed, we have to work with a <em>StatefulSet</em>. To find this out we could also look at the <em>Pod</em> labels:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 get pod --show-labels | grep o3db
</span></span><span style="display:flex;"><span>o3db-0                                  1/1     Running   <span style="color:#ae81ff">0</span>          3m29s   app<span style="color:#f92672">=</span>nginx,controller-revision-hash<span style="color:#f92672">=</span>o3db-5fbd4bb9cc,statefulset.kubernetes.io/pod-name<span style="color:#f92672">=</span>o3db-0
</span></span><span style="display:flex;"><span>o3db-1                                  1/1     Running   <span style="color:#ae81ff">0</span>          3m19s   app<span style="color:#f92672">=</span>nginx,controller-revision-hash<span style="color:#f92672">=</span>o3db-5fbd4bb9cc,statefulset.kubernetes.io/pod-name<span style="color:#f92672">=</span>o3db-1
</span></span></code></pre></div><p>To fulfil the task we simply run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 scale sts o3db --replicas <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>statefulset.apps/o3db scaled
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-c13 get sts o3db
</span></span><span style="display:flex;"><span>NAME   READY   AGE
</span></span><span style="display:flex;"><span>o3db   1/1     4m39s
</span></span></code></pre></div><p>C13 Mangement is happy again.</p>
<h2 id="question-4--pod-ready-if-service-is-reachable">Question 4 | Pod Ready if Service is reachable</h2>
<h3 id="question-3">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Do the following in <em>Namespace</em> <code>default</code>. Create a single <em>Pod</em> named <code>ready-if-service-ready</code> of image <code>nginx:1.16.1-alpine</code>. Configure a LivenessProbe which simply executes command <code>true</code>. Also configure a ReadinessProbe which does check if the url <code>http://service-am-i-ready:80</code> is reachable, you can use <code>wget -T2 -O- http://service-am-i-ready:80</code> for this. Start the <em>Pod</em> and confirm it isn&rsquo;t ready because of the ReadinessProbe.</p>
<p>Create a second <em>Pod</em> named <code>am-i-ready</code> of image <code>nginx:1.16.1-alpine</code> with label <code>id: cross-server-ready</code>. The already existing <em>Service</em> <code>service-am-i-ready</code> should now have that second <em>Pod</em> as endpoint.</p>
<p>Now the first <em>Pod</em> should be in ready state, confirm that.</p>
<h3 id="my-answer-3">My Answer</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/</a></p>
<p>ready-if-service-ready.yaml</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ready-if-service-ready</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.16.1-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ready-if-service-ready</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">sh</span>
</span></span><span style="display:flex;"><span>        - -<span style="color:#ae81ff">c</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;wget -T2 -O- http://service-am-i-ready:80&#39;</span>
</span></span></code></pre></div><p>am-i-ready.yaml</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">am-i-ready</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">id</span>: <span style="color:#ae81ff">cross-server-ready</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.16.1-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">am-i-ready</span>
</span></span></code></pre></div><h3 id="answer-3">Answer</h3>
<p>It&rsquo;s a bit of an anti-pattern for one <em>Pod</em> to check another <em>Pod</em> for being ready using probes, hence the normally available <code>readinessProbe.httpGet</code> doesn&rsquo;t work for absolute remote urls. Still the workaround requested in this task should show how probes and <em>Pod</em>&lt;-&gt;<em>Service</em> communication works.</p>
<p>First we create the first <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run ready-if-service-ready --image<span style="color:#f92672">=</span>nginx:1.16.1-alpine $do &gt; 4_pod1.yaml
</span></span><span style="display:flex;"><span>vim 4_pod1.yaml
</span></span></code></pre></div><p>Next perform the necessary additions manually:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 4_pod1.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">ready-if-service-ready</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ready-if-service-ready</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.16.1-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ready-if-service-ready</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">livenessProbe</span>:                                      <span style="color:#75715e"># add from here</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">sh</span>
</span></span><span style="display:flex;"><span>        - -<span style="color:#ae81ff">c</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;wget -T2 -O- http://service-am-i-ready:80&#39;</span>   <span style="color:#75715e"># to here</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>Then create the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 4_pod1.yaml create
</span></span></code></pre></div><p>And confirm it&rsquo;s in a non-ready state:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod ready-if-service-ready
</span></span><span style="display:flex;"><span>NAME                     READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>ready-if-service-ready   0/1     Running   <span style="color:#ae81ff">0</span>          7s
</span></span></code></pre></div><p>We can also check the reason for this using describe:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k describe pod ready-if-service-ready
</span></span><span style="display:flex;"><span> ...
</span></span><span style="display:flex;"><span>  Warning  Unhealthy  18s   kubelet, cluster1-node1  Readiness probe failed: Connecting to service-am-i-ready:80 <span style="color:#f92672">(</span>10.109.194.234:80<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>wget: download timed out
</span></span></code></pre></div><p>Now we create the second <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run am-i-ready --image<span style="color:#f92672">=</span>nginx:1.16.1-alpine --labels<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;id=cross-server-ready&#34;</span>
</span></span></code></pre></div><p>The already existing <em>Service</em> <code>service-am-i-ready</code> should now have an <em>Endpoint</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k describe svc service-am-i-ready
</span></span><span style="display:flex;"><span>k get ep <span style="color:#75715e"># also possible</span>
</span></span></code></pre></div><p>Which will result in our first <em>Pod</em> being ready, just give it a minute for the Readiness probe to check again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod ready-if-service-ready
</span></span><span style="display:flex;"><span>NAME                     READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>ready-if-service-ready   1/1     Running   <span style="color:#ae81ff">0</span>          53s
</span></span></code></pre></div><p>Look at these <em>Pods</em> coworking together!</p>
<h2 id="question-5--kubectl-sorting">Question 5 | Kubectl sorting</h2>
<h3 id="question-4">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>There are various <em>Pods</em> in all namespaces. Write a command into <code>/opt/course/5/find_pods.sh</code> which lists all <em>Pods</em> sorted by their AGE (<code>metadata.creationTimestamp</code>).</p>
<p>Write a second command into <code>/opt/course/5/find_pods_uid.sh</code> which lists all <em>Pods</em> sorted by field <code>metadata.uid</code>. Use <code>kubectl</code> sorting for both commands.</p>
<h3 id="my-answer-4">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vi /opt/course/5/find_pods.sh
</span></span><span style="display:flex;"><span>kukectl get pod -A --sort-by<span style="color:#f92672">=</span>metadata.creationTimestamp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vi /opt/course/5/find_pods_uid.sh
</span></span><span style="display:flex;"><span>kubectl get pod -A --sort-by<span style="color:#f92672">=</span>metadata.uid
</span></span></code></pre></div><h3 id="answer-4">Answer</h3>
<p>A good resources here (and for many other things) is the kubectl-cheat-sheet. You can reach it fast when searching for &ldquo;cheat sheet&rdquo; in the Kubernetes docs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/5/find_pods.sh</span>
</span></span><span style="display:flex;"><span>kubectl get pod -A --sort-by<span style="color:#f92672">=</span>.metadata.creationTimestamp
</span></span></code></pre></div><p>And to execute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ sh /opt/course/5/find_pods.sh
</span></span><span style="display:flex;"><span>NAMESPACE         NAME                                             ...          AGE
</span></span><span style="display:flex;"><span>kube-system       kube-scheduler-cluster1-controlplane1            ...          63m
</span></span><span style="display:flex;"><span>kube-system       etcd-cluster1-controlplane1                      ...          63m
</span></span><span style="display:flex;"><span>kube-system       kube-apiserver-cluster1-controlplane1            ...          63m
</span></span><span style="display:flex;"><span>kube-system       kube-controller-manager-cluster1-controlplane1   ...          63m
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>For the second command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/5/find_pods_uid.sh</span>
</span></span><span style="display:flex;"><span>kubectl get pod -A --sort-by<span style="color:#f92672">=</span>.metadata.uid
</span></span></code></pre></div><p>And to execute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ sh /opt/course/5/find_pods_uid.sh
</span></span><span style="display:flex;"><span>NAMESPACE         NAME                                      ...          AGE
</span></span><span style="display:flex;"><span>kube-system       coredns-5644d7b6d9-vwm7g                  ...          68m
</span></span><span style="display:flex;"><span>project-c13       c13-3cc-runner-heavy-5486d76dd4-ddvlt     ...          63m
</span></span><span style="display:flex;"><span>project-hamster   web-hamster-shop-849966f479-278vp         ...          63m
</span></span><span style="display:flex;"><span>project-c13       c13-3cc-web-646b6c8756-qsg4b              ...          63m 
</span></span></code></pre></div><h2 id="question-6--storage-pv-pvc-pod-volume">Question 6 | Storage, PV, PVC, Pod volume</h2>
<h3 id="question-5">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Create a new <em>PersistentVolume</em> named <code>safari-pv</code>. It should have a capacity of <em>2Gi</em>, accessMode <em>ReadWriteOnce</em>, hostPath <code>/Volumes/Data</code> and no storageClassName defined.</p>
<p>Next create a new <em>PersistentVolumeClaim</em> in <em>Namespace</em> <code>project-tiger</code> named <code>safari-pvc</code> . It should request <em>2Gi</em> storage, accessMode <em>ReadWriteOnce</em> and should not define a storageClassName. The <em>PVC</em> should bound to the <em>PV</em> correctly.</p>
<p>Finally create a new <em>Deployment</em> <code>safari</code> in <em>Namespace</em> <code>project-tiger</code> which mounts that volume at <code>/tmp/safari-data</code>. The <em>Pods</em> of that <em>Deployment</em> should be of image <code>httpd:2.4.41-alpine</code>.</p>
<h3 id="ref">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-persistent-volume-storage/">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-persistent-volume-storage/</a></p>
<h3 id="answer-5">Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vim 6_pv.yaml
</span></span></code></pre></div><p>Find an example from <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a> and alter it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 6_pv.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolume</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">safari-pv</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">capacity</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">2Gi</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">path</span>: <span style="color:#e6db74">&#34;/Volumes/Data&#34;</span>
</span></span></code></pre></div><p>Then create it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 6_pv.yaml create
</span></span></code></pre></div><p>Next the <em>PersistentVolumeClaim</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vim 6_pvc.yaml
</span></span></code></pre></div><p>Find an example from <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a> and alter it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 6_pvc.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">safari-pvc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-tiger</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">2Gi</span>
</span></span></code></pre></div><p>Then create:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 6_pvc.yaml create
</span></span></code></pre></div><p>And check that both have the status Bound:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-tiger get pv,pvc
</span></span><span style="display:flex;"><span>NAME                         CAPACITY  ... STATUS   CLAIM                    ...
</span></span><span style="display:flex;"><span>persistentvolume/safari-pv   2Gi       ... Bound    project-tiger/safari-pvc ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                               STATUS   VOLUME      CAPACITY ...
</span></span><span style="display:flex;"><span>persistentvolumeclaim/safari-pvc   Bound    safari-pv   2Gi      ...
</span></span></code></pre></div><p>Next we create a <em>Deployment</em> and mount that volume:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-tiger create deploy safari <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --image<span style="color:#f92672">=</span>httpd:2.4.41-alpine $do &gt; 6_dep.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 6_dep.yaml
</span></span></code></pre></div><p>Alter the yaml to mount the volume:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 6_dep.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">safari</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">safari</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-tiger</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">safari</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">safari</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:                                      <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">data                                 </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">persistentVolumeClaim</span>:                      <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">claimName</span>: <span style="color:#ae81ff">safari-pvc                    </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:2.4.41-alpine</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:                               <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">data                               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/tmp/safari-data              </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">k -f 6_dep.yaml create</span>
</span></span></code></pre></div><p>We can confirm it&rsquo;s mounting correctly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-tiger describe pod safari-5cbf46d6d-mjhsb  | grep -A2 Mounts:   
</span></span><span style="display:flex;"><span>    Mounts:
</span></span><span style="display:flex;"><span>      /tmp/safari-data from data <span style="color:#f92672">(</span>rw<span style="color:#f92672">)</span> <span style="color:#75715e"># there it is</span>
</span></span><span style="display:flex;"><span>      /var/run/secrets/kubernetes.io/serviceaccount from default-token-n2sjj <span style="color:#f92672">(</span>ro<span style="color:#f92672">)</span>
</span></span></code></pre></div><h2 id="question-7--node-and-pod-resource-usage">Question 7 | Node and Pod Resource Usage</h2>
<h3 id="question-6">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>The metrics-server has been installed in the cluster. Your college would like to know the kubectl commands to:</p>
<ol>
<li>show <em>Nodes</em> resource usage</li>
<li>show <em>Pods</em> and their containers resource usage</li>
</ol>
<p>Please write the commands into <code>/opt/course/7/node.sh</code> and <code>/opt/course/7/pod.sh</code>.</p>
<h3 id="my-answer-5">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vi /opt/course/7/node.sh
</span></span><span style="display:flex;"><span>kubectl top node
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vi /opt/course/7/pod.sh
</span></span><span style="display:flex;"><span>kubectl top pod --containers<span style="color:#f92672">=</span>true
</span></span></code></pre></div><h3 id="answer-6">Answer</h3>
<p>The command we need to use here is top:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k top -h
</span></span><span style="display:flex;"><span>Display Resource <span style="color:#f92672">(</span>CPU/Memory/Storage<span style="color:#f92672">)</span> usage.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> The top command allows you to see the resource consumption <span style="color:#66d9ef">for</span> nodes or pods.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> This command requires Metrics Server to be correctly configured and working on the server.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Available Commands:
</span></span><span style="display:flex;"><span>  node        Display Resource <span style="color:#f92672">(</span>CPU/Memory/Storage<span style="color:#f92672">)</span> usage of nodes
</span></span><span style="display:flex;"><span>  pod         Display Resource <span style="color:#f92672">(</span>CPU/Memory/Storage<span style="color:#f92672">)</span> usage of pods
</span></span></code></pre></div><p>We see that the metrics server provides information about resource usage:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k top node
</span></span><span style="display:flex;"><span>NAME               CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   CPU%   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>   MEMORY%   
</span></span><span style="display:flex;"><span>cluster1-controlplane1   178m         8%     1091Mi          57%       
</span></span><span style="display:flex;"><span>cluster1-node1   66m          6%     834Mi           44%       
</span></span><span style="display:flex;"><span>cluster1-node2   91m          9%     791Mi           41% 
</span></span></code></pre></div><p>We create the first file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/7/node.sh</span>
</span></span><span style="display:flex;"><span>kubectl top node
</span></span></code></pre></div><p>For the second file we might need to check the docs again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k top pod -h
</span></span><span style="display:flex;"><span>Display Resource <span style="color:#f92672">(</span>CPU/Memory/Storage<span style="color:#f92672">)</span> usage of pods.
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Namespace in current context is ignored even <span style="color:#66d9ef">if</span> specified with --namespace.
</span></span><span style="display:flex;"><span>      --containers<span style="color:#f92672">=</span>false: If present, print usage of containers within a pod.
</span></span><span style="display:flex;"><span>      --no-headers<span style="color:#f92672">=</span>false: If present, print output without headers.
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>With this we can finish this task:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/7/pod.sh</span>
</span></span><span style="display:flex;"><span>kubectl top pod --containers<span style="color:#f92672">=</span>true 
</span></span></code></pre></div><h2 id="question-8--get-controlplane-information">Question 8 | Get Controlplane Information</h2>
<h3 id="question-7">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Ssh into the controlplane node with <code>ssh cluster1-controlplane1</code>. Check how the controlplane components kubelet, kube-apiserver, kube-scheduler, kube-controller-manager and etcd are started/installed on the controlplane node. Also find out the name of the DNS application and how it&rsquo;s started/installed on the controlplane node.</p>
<p>Write your findings into file <code>/opt/course/8/controlplane-components.txt</code>. The file should be structured like:</p>
<pre tabindex="0"><code># /opt/course/8/controlplane-components.txt
kubelet: [TYPE]
kube-apiserver: [TYPE]
kube-scheduler: [TYPE]
kube-controller-manager: [TYPE]
etcd: [TYPE]
dns: [TYPE] [NAME]
</code></pre><p>Choices of <code>[TYPE]</code> are: <code>not-installed</code>, <code>process</code>, <code>static-pod</code>, <code>pod</code></p>
<h3 id="my-answer-6">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ssh cluster1-controlplane1
</span></span><span style="display:flex;"><span>sudo -i
</span></span><span style="display:flex;"><span>systemctl status kubelet  <span style="color:#75715e"># kubelet is in process</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>find /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>kubectl get pod -n kube-system -o wide  <span style="color:#75715e"># kube-apiserver, kube-scheduler, kube-controller-manager and etcd are static-pod</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get deploy,ds,sts -n kube-system  <span style="color:#75715e"># see coredns</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit  <span style="color:#75715e"># exit sudo</span>
</span></span><span style="display:flex;"><span>exit  <span style="color:#75715e"># exit cluster1-controlplane1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vi /opt/course/8/controlplane-components.txt
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/8/controlplane-components.txt</span>
</span></span><span style="display:flex;"><span>kubelet: process
</span></span><span style="display:flex;"><span>kube-apiserver: static-pod
</span></span><span style="display:flex;"><span>kube-scheduler: static-pod
</span></span><span style="display:flex;"><span>kube-controller-manager: static-pod
</span></span><span style="display:flex;"><span>etcd: static-pod
</span></span><span style="display:flex;"><span>dns: pod coredns
</span></span></code></pre></div><h3 id="answer-7">Answer</h3>
<p>We could start by finding processes of the requested components, especially the kubelet at first:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1
</span></span><span style="display:flex;"><span>root@cluster1-controlplane1:~# ps aux | grep kubelet <span style="color:#75715e"># shows kubelet process</span>
</span></span></code></pre></div><p>We can see which components are controlled via systemd looking at <code>/usr/lib/systemd</code> directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# find /usr/lib/systemd | grep kube
</span></span><span style="display:flex;"><span>/usr/lib/systemd/system/kubelet.service
</span></span><span style="display:flex;"><span>/usr/lib/systemd/system/kubelet.service.d
</span></span><span style="display:flex;"><span>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# find /usr/lib/systemd | grep etcd
</span></span></code></pre></div><p>This shows kubelet is controlled via systemd, but no other service named kube nor etcd. It seems that this cluster has been setup using kubeadm, so we check in the default manifests directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# find /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-controller-manager.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/etcd.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-scheduler.yaml
</span></span></code></pre></div><p>(The kubelet could also have a different manifests directory specified via parameter <code>--pod-manifest-path</code> in it&rsquo;s systemd startup config)</p>
<p>This means the main 4 controlplane services are setup as static <em>Pods</em>. Actually, let&rsquo;s check all <em>Pods</em> running on in the <code>kube-system</code> <em>Namespace</em> on the controlplane node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# kubectl -n kube-system get pod -o wide | grep controlplane1
</span></span><span style="display:flex;"><span>coredns-5644d7b6d9-c4f68                            1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>coredns-5644d7b6d9-t84sc                            1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>etcd-cluster1-controlplane1                         1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>kube-apiserver-cluster1-controlplane1               1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>kube-controller-manager-cluster1-controlplane1      1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>kube-proxy-q955p                                    1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>kube-scheduler-cluster1-controlplane1               1/1     Running            ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>weave-net-mwj47                                     2/2     Running            ...   cluster1-controlplane1
</span></span></code></pre></div><p>There we see the 5 static pods, with <code>-cluster1-controlplane1</code> as suffix.</p>
<p>We also see that the dns application seems to be coredns, but how is it controlled?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster1-controlplane1$ kubectl -n kube-system get ds
</span></span><span style="display:flex;"><span>NAME         DESIRED   CURRENT   ...   NODE SELECTOR            AGE
</span></span><span style="display:flex;"><span>kube-proxy   <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>         ...   kubernetes.io/os<span style="color:#f92672">=</span>linux   155m
</span></span><span style="display:flex;"><span>weave-net    <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>         ...   &lt;none&gt;                   155m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1$ kubectl -n kube-system get deploy
</span></span><span style="display:flex;"><span>NAME      READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style="display:flex;"><span>coredns   2/2     <span style="color:#ae81ff">2</span>            <span style="color:#ae81ff">2</span>           155m
</span></span></code></pre></div><p>Seems like coredns is controlled via a <em>Deployment</em>. We combine our findings in the requested file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/8/controlplane-components.txt</span>
</span></span><span style="display:flex;"><span>kubelet: process
</span></span><span style="display:flex;"><span>kube-apiserver: static-pod
</span></span><span style="display:flex;"><span>kube-scheduler: static-pod
</span></span><span style="display:flex;"><span>kube-controller-manager: static-pod
</span></span><span style="display:flex;"><span>etcd: static-pod
</span></span><span style="display:flex;"><span>dns: pod coredns
</span></span></code></pre></div><p>You should be comfortable investigating a running cluster, know different methods on how a cluster and its services can be setup and be able to troubleshoot and find error sources.</p>
<h2 id="question-9--kill-scheduler-manual-scheduling">Question 9 | Kill Scheduler, Manual Scheduling</h2>
<h3 id="question-8">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>Ssh into the controlplane node with <code>ssh cluster2-controlplane1</code>. <strong>Temporarily</strong> stop the kube-scheduler, this means in a way that you can start it again afterwards.</p>
<p>Create a single <em>Pod</em> named <code>manual-schedule</code> of image <code>httpd:2.4-alpine</code>, confirm it&rsquo;s created but not scheduled on any node.</p>
<p>Now you&rsquo;re the scheduler and have all its power, manually schedule that <em>Pod</em> on node <code>cluster2-controlplane1</code>. Make sure it&rsquo;s running.</p>
<p>Start the kube-scheduler again and confirm it&rsquo;s running correctly by creating a second <em>Pod</em> named <code>manual-schedule2</code> of image <code>httpd:2.4-alpine</code> and check if it&rsquo;s running on <code>cluster2-node1</code>.</p>
<h3 id="my-answer-7">My Answer</h3>
<p>Temporarily stop the kube-scheduler (do not use <code>rm</code>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ssh cluster2-controlplane1
</span></span><span style="display:flex;"><span>sudo -i 
</span></span><span style="display:flex;"><span>kubectl -n kube-system get pod | grep schedule
</span></span><span style="display:flex;"><span>cd /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>mv kube-scheduler.yaml ..
</span></span><span style="display:flex;"><span>kubectl -n kube-system get pod | grep schedule
</span></span></code></pre></div><p>Create pod</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubectl run manual-schedule --image<span style="color:#f92672">=</span>httpd:2.4-alpine
</span></span><span style="display:flex;"><span>kubectl get pod manual-schedule
</span></span></code></pre></div><p>Edit pod by <code>kubectl edit</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeName</span>: <span style="color:#ae81ff">cluster2-controlplane1 </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>Start the kube-scheduler again</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd /etc/kubernetes
</span></span><span style="display:flex;"><span>mv kube-scheduler.yaml /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>kubectl run manual-schedule2 --image<span style="color:#f92672">=</span>httpd:2.4-alpine
</span></span><span style="display:flex;"><span>kubectl get pod manual-schedule2
</span></span></code></pre></div><p>Remember to exit.</p>
<h3 id="answer-8">Answer</h3>
<h4 id="stop-the-scheduler">Stop the Scheduler</h4>
<p>First we find the controlplane node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE   VERSION
</span></span><span style="display:flex;"><span>cluster2-controlplane1   Ready    control-plane   26h   v1.29.0
</span></span><span style="display:flex;"><span>cluster2-node1           Ready    &lt;none&gt;          26h   v1.29.0
</span></span></code></pre></div><p>Then we connect and check if the scheduler is running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubectl -n kube-system get pod | grep schedule
</span></span><span style="display:flex;"><span>kube-scheduler-cluster2-controlplane1            1/1     Running   <span style="color:#ae81ff">0</span>          6s
</span></span></code></pre></div><p>Kill the Scheduler (temporarily):</p>
<pre tabindex="0"><code>➜ root@cluster2-controlplane1:~# cd /etc/kubernetes/manifests/

➜ root@cluster2-controlplane1:~# mv kube-scheduler.yaml ..
</code></pre><p>And it should be stopped:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubectl -n kube-system get pod | grep schedule
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# 
</span></span></code></pre></div><h4 id="create-a-pod">Create a <em>Pod</em></h4>
<p>Now we create the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run manual-schedule --image<span style="color:#f92672">=</span>httpd:2.4-alpine
</span></span></code></pre></div><p>And confirm it has no node assigned:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod manual-schedule -o wide
</span></span><span style="display:flex;"><span>NAME              READY   STATUS    ...   NODE     NOMINATED NODE
</span></span><span style="display:flex;"><span>manual-schedule   0/1     Pending   ...   &lt;none&gt;   &lt;none&gt;        
</span></span></code></pre></div><h4 id="manually-schedule-the-pod">Manually schedule the <em>Pod</em></h4>
<p>Let&rsquo;s play the scheduler now:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">k get pod manual-schedule -o yaml &gt; 9.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 9.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#e6db74">&#34;2020-09-04T15:51:02Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">manual-schedule</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">managedFields</span>:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">manager</span>: <span style="color:#ae81ff">kubectl-run</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">operation</span>: <span style="color:#ae81ff">Update</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">time</span>: <span style="color:#e6db74">&#34;2020-09-04T15:51:02Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">manual-schedule</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resourceVersion</span>: <span style="color:#e6db74">&#34;3515&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selfLink</span>: <span style="color:#ae81ff">/api/v1/namespaces/default/pods/manual-schedule</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">uid</span>: <span style="color:#ae81ff">8e9d2532-4779-4e63-b5af-feb82c74a935</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeName</span>: <span style="color:#ae81ff">cluster2-controlplane1       </span> <span style="color:#75715e"># add the controlplane node name</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:2.4-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">manual-schedule</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">terminationMessagePath</span>: <span style="color:#ae81ff">/dev/termination-log</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">terminationMessagePolicy</span>: <span style="color:#ae81ff">File</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/run/secrets/kubernetes.io/serviceaccount</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-token-nxnc7</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>The only thing a scheduler does, is that it sets the nodeName for a <em>Pod</em> declaration. How it finds the correct node to schedule on, that&rsquo;s a very much complicated matter and takes many variables into account.</p>
<p>As we cannot <code>kubectl apply</code> or <code>kubectl edit</code> , in this case we need to delete and create or replace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 9.yaml replace --force
</span></span></code></pre></div><p>How does it look?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod manual-schedule -o wide
</span></span><span style="display:flex;"><span>NAME              READY   STATUS    ...   NODE            
</span></span><span style="display:flex;"><span>manual-schedule   1/1     Running   ...   cluster2-controlplane1
</span></span></code></pre></div><p>It looks like our <em>Pod</em> is running on the controlplane now as requested, although no tolerations were specified. Only the scheduler takes tains/tolerations/affinity into account when finding the correct node name. That&rsquo;s why it&rsquo;s still possible to assign <em>Pods</em> manually directly to a controlplane node and skip the scheduler.</p>
<h4 id="start-the-scheduler-again">Start the scheduler again</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# cd /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# mv ../kube-scheduler.yaml .
</span></span></code></pre></div><p>Checks it&rsquo;s running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubectl -n kube-system get pod | grep schedule
</span></span><span style="display:flex;"><span>kube-scheduler-cluster2-controlplane1            1/1     Running   <span style="color:#ae81ff">0</span>          16s
</span></span></code></pre></div><p>Schedule a second test <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run manual-schedule2 --image<span style="color:#f92672">=</span>httpd:2.4-alpine
</span></span><span style="display:flex;"><span>➜ k get pod -o wide | grep schedule
</span></span><span style="display:flex;"><span>manual-schedule    1/1     Running   ...   cluster2-controlplane1
</span></span><span style="display:flex;"><span>manual-schedule2   1/1     Running   ...   cluster2-node1
</span></span></code></pre></div><p>Back to normal.</p>
<h2 id="question-10--rbac-serviceaccount-role-rolebinding">Question 10 | RBAC ServiceAccount Role RoleBinding</h2>
<h3 id="question-9">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Create a new <em>ServiceAccount</em> <code>processor</code> in <em>Namespace</em> <code>project-hamster</code>. Create a <em>Role</em> and <em>RoleBinding</em>, both named <code>processor</code> as well. These should allow the new <em>SA</em> to only create <em>Secrets</em> and <em>ConfigMaps</em> in that <em>Namespace</em>.</p>
<h3 id="my-answer-8">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kc create sa processor -n project-hamster
</span></span><span style="display:flex;"><span>kc create role processor -n project-hamster --verb<span style="color:#f92672">=</span>create --resource<span style="color:#f92672">=</span>secrets,configmaps
</span></span><span style="display:flex;"><span>kc create rolebinding processor -n project-hamster --role<span style="color:#f92672">=</span>processor --serviceaccount<span style="color:#f92672">=</span>project-hamster:processor
</span></span></code></pre></div><h3 id="answer-9">Answer</h3>
<p><strong>Let&rsquo;s talk a little about RBAC resources</strong></p>
<p>A <em>ClusterRole</em>|<em>Role</em> defines a set of permissions and <strong>where it is available</strong>, in the whole cluster or just a single <em>Namespace</em>.</p>
<p>A <em>ClusterRoleBinding</em>|<em>RoleBinding</em> connects a set of permissions with an account and defines <strong>where it is applied</strong>, in the whole cluster or just a single <em>Namespace</em>.</p>
<p>Because of this there are 4 different RBAC combinations and 3 valid ones:</p>
<ol>
<li><em>Role</em> + <em>RoleBinding</em> (available in single <em>Namespace</em>, applied in single <em>Namespace</em>)</li>
<li><em>ClusterRole</em> + <em>ClusterRoleBinding</em> (available cluster-wide, applied cluster-wide)</li>
<li><em>ClusterRole</em> + <em>RoleBinding</em> (available cluster-wide, applied in single <em>Namespace</em>)</li>
<li><em>Role</em> + <em>ClusterRoleBinding</em> (<strong>NOT POSSIBLE:</strong> available in single <em>Namespace</em>, applied cluster-wide)</li>
</ol>
<p><strong>To the solution</strong></p>
<p>We first create the <em>ServiceAccount</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-hamster create sa processor
</span></span><span style="display:flex;"><span>serviceaccount/processor created
</span></span></code></pre></div><p>Then for the <em>Role</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster create role -h <span style="color:#75715e"># examples</span>
</span></span></code></pre></div><p>So we execute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster create role processor <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --verb<span style="color:#f92672">=</span>create <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --resource<span style="color:#f92672">=</span>secret <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --resource<span style="color:#f92672">=</span>configmap
</span></span></code></pre></div><p>Which will create a <em>Role</em> like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># kubectl -n project-hamster create role processor --verb=create --resource=secret --resource=configmap</span>
</span></span><span style="display:flex;"><span>apiVersion: rbac.authorization.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Role
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: processor
</span></span><span style="display:flex;"><span>  namespace: project-hamster
</span></span><span style="display:flex;"><span>rules:
</span></span><span style="display:flex;"><span>- apiGroups:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  resources:
</span></span><span style="display:flex;"><span>  - secrets
</span></span><span style="display:flex;"><span>  - configmaps
</span></span><span style="display:flex;"><span>  verbs:
</span></span><span style="display:flex;"><span>  - create
</span></span></code></pre></div><p>Now we bind the <em>Role</em> to the <em>ServiceAccount</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster create rolebinding -h <span style="color:#75715e"># examples</span>
</span></span></code></pre></div><p>So we create it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster create rolebinding processor <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --role processor <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --serviceaccount project-hamster:processor
</span></span></code></pre></div><p>This will create a <em>RoleBinding</em> like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># kubectl -n project-hamster create rolebinding processor --role processor --serviceaccount project-hamster:processor</span>
</span></span><span style="display:flex;"><span>apiVersion: rbac.authorization.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: RoleBinding
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: processor
</span></span><span style="display:flex;"><span>  namespace: project-hamster
</span></span><span style="display:flex;"><span>roleRef:
</span></span><span style="display:flex;"><span>  apiGroup: rbac.authorization.k8s.io
</span></span><span style="display:flex;"><span>  kind: Role
</span></span><span style="display:flex;"><span>  name: processor
</span></span><span style="display:flex;"><span>subjects:
</span></span><span style="display:flex;"><span>- kind: ServiceAccount
</span></span><span style="display:flex;"><span>  name: processor
</span></span><span style="display:flex;"><span>  namespace: project-hamster
</span></span></code></pre></div><p>To test our RBAC setup we can use <code>kubectl auth can-i</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k auth can-i -h <span style="color:#75715e"># examples</span>
</span></span></code></pre></div><p>Like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-hamster auth can-i create secret <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --as system:serviceaccount:project-hamster:processor
</span></span><span style="display:flex;"><span>yes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-hamster auth can-i create configmap <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --as system:serviceaccount:project-hamster:processor
</span></span><span style="display:flex;"><span>yes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-hamster auth can-i create pod <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --as system:serviceaccount:project-hamster:processor
</span></span><span style="display:flex;"><span>no
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-hamster auth can-i delete secret <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --as system:serviceaccount:project-hamster:processor
</span></span><span style="display:flex;"><span>no
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-hamster auth can-i get configmap <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --as system:serviceaccount:project-hamster:processor
</span></span><span style="display:flex;"><span>no
</span></span></code></pre></div><p>Done.</p>
<h2 id="question-11--daemonset-on-all-nodes">Question 11 | DaemonSet on all Nodes</h2>
<h3 id="question-10">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Use <em>Namespace</em> <code>project-tiger</code> for the following. Create a <em>DaemonSet</em> named <code>ds-important</code> with image <code>httpd:2.4-alpine</code> and labels <code>id=ds-important</code> and <code>uuid=18426a0b-5f59-4e10-923f-c0e078e82462</code>. The <em>Pods</em> it creates should request 10 millicore cpu and 10 mebibyte memory. The <em>Pods</em> of that <em>DaemonSet</em> should run on all nodes, also controlplanes.</p>
<h3 id="ref-1">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/daemonset/">https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/daemonset/</a></p>
<h3 id="answer-10">Answer</h3>
<p>As of now we aren&rsquo;t able to create a <em>DaemonSet</em> directly using <code>kubectl</code>, so we create a <em>Deployment</em> and just change it up:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-tiger create deployment --image<span style="color:#f92672">=</span>httpd:2.4-alpine ds-important $do &gt; 11.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 11.yaml
</span></span></code></pre></div><p>(Sure you could also search for a <em>DaemonSet</em> example yaml in the Kubernetes docs and alter it.)</p>
<p>Then we adjust the yaml to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 11.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">DaemonSet                                    </span> <span style="color:#75715e"># change from Deployment to Daemonset</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:                                           <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">id</span>: <span style="color:#ae81ff">ds-important                               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">uuid</span>: <span style="color:#ae81ff">18426a0b-5f59-4e10-923f-c0e078e82462     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ds-important</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-tiger                         </span> <span style="color:#75715e"># important</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#replicas: 1                                      # remove</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">id</span>: <span style="color:#ae81ff">ds-important                             </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">uuid</span>: <span style="color:#ae81ff">18426a0b-5f59-4e10-923f-c0e078e82462   </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#strategy: {}                                     # remove</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">id</span>: <span style="color:#ae81ff">ds-important                           </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">uuid</span>: <span style="color:#ae81ff">18426a0b-5f59-4e10-923f-c0e078e82462 </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:2.4-alpine</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ds-important</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">requests</span>:                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">10m                               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">10Mi                           </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">tolerations</span>:                                  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">effect</span>: <span style="color:#ae81ff">NoSchedule                         </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">key</span>: <span style="color:#ae81ff">node-role.kubernetes.io/control-plane </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#status: {}                                         # remove</span>
</span></span></code></pre></div><p>It was requested that the <em>DaemonSet</em> runs on all nodes, so we need to specify the toleration for this.</p>
<p>Let&rsquo;s confirm:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 11.yaml create
</span></span><span style="display:flex;"><span>➜ k -n project-tiger get ds
</span></span><span style="display:flex;"><span>NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
</span></span><span style="display:flex;"><span>ds-important   <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>       <span style="color:#ae81ff">3</span>            <span style="color:#ae81ff">3</span>           &lt;none&gt;          8s
</span></span><span style="display:flex;"><span>➜ k -n project-tiger get pod -l id<span style="color:#f92672">=</span>ds-important -o wide
</span></span><span style="display:flex;"><span>NAME                      READY   STATUS          NODE
</span></span><span style="display:flex;"><span>ds-important-6pvgm        1/1     Running   ...   cluster1-node1
</span></span><span style="display:flex;"><span>ds-important-lh5ts        1/1     Running   ...   cluster1-controlplane1
</span></span><span style="display:flex;"><span>ds-important-qhjcq        1/1     Running   ...   cluster1-node2 
</span></span></code></pre></div><h2 id="question-12--deployment-on-all-nodes">Question 12 | Deployment on all Nodes</h2>
<h3 id="question-11">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Use <em>Namespace</em> <code>project-tiger</code> for the following. Create a <em>Deployment</em> named <code>deploy-important</code> with label <code>id=very-important</code> (the <code>Pods</code> should also have this label) and 3 replicas. It should contain two containers, the first named <code>container1</code> with image <code>nginx:1.17.6-alpine</code> and the second one named container2 with image <code>google/pause</code>.</p>
<p>There should be only ever <strong>one</strong> <em>Pod</em> of that <em>Deployment</em> running on <strong>one</strong> worker node. We have two worker nodes: <code>cluster1-node1</code> and <code>cluster1-node2</code>. Because the <em>Deployment</em> has three replicas the result should be that on both nodes <strong>one</strong> <em>Pod</em> is running. The third <em>Pod</em> won&rsquo;t be scheduled, unless a new worker node will be added. Use <code>topologyKey: kubernetes.io/hostname</code> for this.</p>
<p>In a way we kind of simulate the behaviour of a <em>DaemonSet</em> here, but using a <em>Deployment</em> and a fixed number of replicas.</p>
<h3 id="ref-2">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/</a></p>
<h3 id="answer-11">Answer</h3>
<p>There are two possible ways, one using <code>podAntiAffinity</code> and one using <code>topologySpreadConstraint</code>.</p>
<h4 id="podantiaffinity">PodAntiAffinity</h4>
<p>The idea here is that we create a &ldquo;Inter-pod anti-affinity&rdquo; which allows us to say a <em>Pod</em> should only be scheduled on a node where another <em>Pod</em> of a specific label (here the same label) is not already running.</p>
<p>Let&rsquo;s begin by creating the <em>Deployment</em> template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-tiger create deployment <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --image<span style="color:#f92672">=</span>nginx:1.17.6-alpine deploy-important $do &gt; 12.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 12.yaml
</span></span></code></pre></div><p>Then change the yaml to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 12.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important                 </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deploy-important</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-tiger             </span> <span style="color:#75715e"># important</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>                           <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important               </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important             </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.17.6-alpine</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">container1               </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">google/pause            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">container2               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">affinity</span>:                                             <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">podAntiAffinity</span>:                                    <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">requiredDuringSchedulingIgnoredDuringExecution</span>:   <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">labelSelector</span>:                                  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">matchExpressions</span>:                             <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">id                                    </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">In                               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">values</span>:                                     <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>                - <span style="color:#ae81ff">very-important                           </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">kubernetes.io/hostname            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>Specify a topologyKey, which is a pre-populated Kubernetes label, you can find this by describing a node.</p>
<h4 id="topologyspreadconstraints">TopologySpreadConstraints</h4>
<p>We can achieve the same with <code>topologySpreadConstraints</code>. Best to try out and play with both.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 12.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important                 </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deploy-important</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-tiger             </span> <span style="color:#75715e"># important</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>                           <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important               </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important             </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.17.6-alpine</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">container1               </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">google/pause            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">container2               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">topologySpreadConstraints</span>:                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">maxSkew</span>: <span style="color:#ae81ff">1</span>                               <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">kubernetes.io/hostname     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">whenUnsatisfiable</span>: <span style="color:#ae81ff">DoNotSchedule        </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">labelSelector</span>:                           <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>:                           <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">id</span>: <span style="color:#ae81ff">very-important                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {} 
</span></span></code></pre></div><h4 id="apply-and-run">Apply and Run</h4>
<p>Let&rsquo;s run it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 12.yaml create
</span></span></code></pre></div><p>Then we check the <em>Deployment</em> status where it shows 2/3 ready count:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-tiger get deploy -l id<span style="color:#f92672">=</span>very-important
</span></span><span style="display:flex;"><span>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style="display:flex;"><span>deploy-important   2/3     <span style="color:#ae81ff">3</span>            <span style="color:#ae81ff">2</span>           2m35s
</span></span></code></pre></div><p>And running the following we see one <em>Pod</em> on each worker node and one not scheduled.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-tiger get pod -o wide -l id<span style="color:#f92672">=</span>very-important
</span></span><span style="display:flex;"><span>NAME                                READY   STATUS    ...   NODE             
</span></span><span style="display:flex;"><span>deploy-important-58db9db6fc-9ljpw   2/2     Running   ...   cluster1-node1
</span></span><span style="display:flex;"><span>deploy-important-58db9db6fc-lnxdb   0/2     Pending   ...   &lt;none&gt;          
</span></span><span style="display:flex;"><span>deploy-important-58db9db6fc-p2rz8   2/2     Running   ...   cluster1-node2
</span></span></code></pre></div><p>If we kubectl describe the <em>Pod</em> <code>deploy-important-58db9db6fc-lnxdb</code> it will show us the reason for not scheduling is our implemented podAntiAffinity ruling:</p>
<pre tabindex="0"><code>Warning  FailedScheduling  63s (x3 over 65s)  default-scheduler  0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/control-plane: }, that the pod didn&#39;t tolerate, 2 node(s) didn&#39;t match pod affinity/anti-affinity, 2 node(s) didn&#39;t satisfy existing pods anti-affinity rules.
</code></pre><p>Or our topologySpreadConstraints:</p>
<pre tabindex="0"><code>Warning  FailedScheduling  16s   default-scheduler  0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/control-plane: }, that the pod didn&#39;t tolerate, 2 node(s) didn&#39;t match pod topology spread constraints. 
</code></pre><h2 id="question-13--multi-containers-and-pod-shared-volume">Question 13 | Multi Containers and Pod shared Volume</h2>
<h3 id="question-12">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Create a <em>Pod</em> named <code>multi-container-playground</code> in <em>Namespace</em> <code>default</code> with three containers, named <code>c1</code>, <code>c2</code> and <code>c3</code>. There should be a volume attached to that <em>Pod</em> and mounted into every container, but the volume shouldn&rsquo;t be persisted or shared with other <em>Pods</em>.</p>
<p>Container <code>c1</code> should be of image <code>nginx:1.17.6-alpine</code> and have the name of the node where its <em>Pod</em> is running available as environment variable <code>MY_NODE_NAME</code>.</p>
<p>Container <code>c2</code> should be of image <code>busybox:1.31.1</code> and write the output of the <code>date</code> command every second in the shared volume into file <code>date.log</code>. You can use <code>while true; do date &gt;&gt; /your/vol/path/date.log; sleep 1; done</code> for this.</p>
<p>Container <code>c3</code> should be of image <code>busybox:1.31.1</code> and constantly send the content of file <code>date.log</code> from the shared volume to stdout. You can use <code>tail -f /your/vol/path/date.log</code> for this.</p>
<p>Check the logs of container <code>c3</code> to confirm correct setup.</p>
<h3 id="my-answer-9">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">multi-container-playground</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.17.6-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># https://kubernetes.io/zh-cn/docs/tasks/inject-data-application/environment-variable-expose-pod-information/</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>: 
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MY_NODE_NAME </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:                                                                  
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">fieldRef</span>:                                                          
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">fieldPath</span>: <span style="color:#ae81ff">spec.nodeName                                             </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                        
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                            </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                </span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31.1                                                         </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;while true; do date &gt;&gt; /vol/date.log; sleep 1; done&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                               
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                     </span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c3</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31.1                                              </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;tail -f /vol/date.log&#34;</span>]                            
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                    
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                          </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                  </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:                                                                     
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">emptyDir</span>: {}                                                        
</span></span></code></pre></div><h3 id="answer-12">Answer</h3>
<p>First we create the <em>Pod</em> template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run multi-container-playground --image<span style="color:#f92672">=</span>nginx:1.17.6-alpine $do &gt; 13.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 13.yaml
</span></span></code></pre></div><p>And add the other containers and the commands they should execute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 13.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">multi-container-playground</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">multi-container-playground</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.17.6-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c1                                                                     </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>:                                                                          <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MY_NODE_NAME                                                         </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:                                                                  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">fieldRef</span>:                                                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">fieldPath</span>: <span style="color:#ae81ff">spec.nodeName                                               </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31.1                                                        </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c2                                                                     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;while true; do date &gt;&gt; /vol/date.log; sleep 1; done&#34;</span>]  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31.1                                                        </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c3                                                                     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;tail -f /vol/date.log&#34;</span>]                                <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                                                                 <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/vol                                                            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:                                                                        <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vol                                                                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">emptyDir</span>: {}                                                                <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">k -f 13.yaml create</span>
</span></span></code></pre></div><p>Oh boy, lot&rsquo;s of requested things. We check if everything is good with the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod multi-container-playground
</span></span><span style="display:flex;"><span>NAME                         READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>multi-container-playground   3/3     Running   <span style="color:#ae81ff">0</span>          95s
</span></span></code></pre></div><p>Good, then we check if container c1 has the requested node name as env variable:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k exec multi-container-playground -c c1 -- env | grep MY
</span></span><span style="display:flex;"><span>MY_NODE_NAME<span style="color:#f92672">=</span>cluster1-node2
</span></span></code></pre></div><p>And finally we check the logging:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k logs multi-container-playground -c c3
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:10 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:11 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:12 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:13 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:14 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:15 UTC <span style="color:#ae81ff">2077</span>
</span></span><span style="display:flex;"><span>Sat Dec  <span style="color:#ae81ff">7</span> 16:05:16 UTC <span style="color:#ae81ff">2077</span> 
</span></span></code></pre></div><h2 id="question-14--find-out-cluster-information">Question 14 | Find out Cluster Information</h2>
<h3 id="question-13">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>You&rsquo;re ask to find out following information about the cluster <code>k8s-c1-H</code>:</p>
<ol>
<li>How many controlplane nodes are available?</li>
<li>How many worker nodes are available?</li>
<li>What is the Service CIDR?</li>
<li>Which Networking (or CNI Plugin) is configured and where is its config file?</li>
<li>Which suffix will static pods have that run on <code>cluster1-node1</code>?</li>
</ol>
<p>Write your answers into file <code>/opt/course/14/cluster-info</code>, structured like this:</p>
<pre tabindex="0"><code># /opt/course/14/cluster-info
1: [ANSWER]
2: [ANSWER]
3: [ANSWER]
4: [ANSWER]
5: [ANSWER]
</code></pre><h3 id="answer-13">Answer</h3>
<p><strong>How many controlplane and worker nodes are available?</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES          AGE   VERSION
</span></span><span style="display:flex;"><span>cluster1-controlplane1  Ready    control-plane  27h   v1.29.0
</span></span><span style="display:flex;"><span>cluster1-node1          Ready    &lt;none&gt;         27h   v1.29.0
</span></span><span style="display:flex;"><span>cluster1-node2          Ready    &lt;none&gt;         27h   v1.29.0
</span></span></code></pre></div><p>We see one controlplane and two workers.</p>
<p><strong>What is the Service CIDR?</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep range
</span></span><span style="display:flex;"><span>    - --service-cluster-ip-range<span style="color:#f92672">=</span>10.96.0.0/12
</span></span></code></pre></div><p><strong>Which Networking (or CNI Plugin) is configured and where is its config file?</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# find /etc/cni/net.d/
</span></span><span style="display:flex;"><span>/etc/cni/net.d/
</span></span><span style="display:flex;"><span>/etc/cni/net.d/10-weave.conflist
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# cat /etc/cni/net.d/10-weave.conflist
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cniVersion&#34;</span>: <span style="color:#e6db74">&#34;0.3.0&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;weave&#34;</span>,
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>By default the kubelet looks into <code>/etc/cni/net.d</code> to discover the CNI plugins. This will be the same on every controlplane and worker nodes.</p>
<p><strong>Which suffix will static pods have that run on cluster1-node1?</strong></p>
<p>The suffix is the node hostname with a leading hyphen. It used to be <code>-static</code> in earlier Kubernetes versions.</p>
<p><strong>Result</strong></p>
<p>The resulting <code>/opt/course/14/cluster-info</code> could look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/14/cluster-info</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># How many controlplane nodes are available?</span>
</span></span><span style="display:flex;"><span>1: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># How many worker nodes are available?</span>
</span></span><span style="display:flex;"><span>2: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># What is the Service CIDR?</span>
</span></span><span style="display:flex;"><span>3: 10.96.0.0/12
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Which Networking (or CNI Plugin) is configured and where is its config file?</span>
</span></span><span style="display:flex;"><span>4: Weave, /etc/cni/net.d/10-weave.conflist
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Which suffix will static pods have that run on cluster1-node1?</span>
</span></span><span style="display:flex;"><span>5: -cluster1-node1
</span></span></code></pre></div><h2 id="question-15--cluster-event-logging">Question 15 | Cluster Event Logging</h2>
<h3 id="question-14">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>Write a command into <code>/opt/course/15/cluster_events.sh</code> which shows the latest events in the whole cluster, ordered by time (<code>metadata.creationTimestamp</code>). Use <code>kubectl</code> for it.</p>
<p>Now delete the kube-proxy <em>Pod</em> running on node cluster2-node1 and write the events this caused into <code>/opt/course/15/pod_kill.log</code>.</p>
<p>Finally kill the containerd container of the kube-proxy <em>Pod</em> on node <code>cluster2-node1</code> and write the events into <code>/opt/course/15/container_kill.log</code>.</p>
<p>Do you notice differences in the events both actions caused?</p>
<h3 id="my-answer-10">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vi /opt/course/15/cluster_events.sh
</span></span><span style="display:flex;"><span>kubectl get events -A --sort-by<span style="color:#f92672">=</span>metadata.creationTimestamp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k get pod -o wide | grep kube-proxy <span style="color:#75715e"># find pod running on cluster2-node1</span>
</span></span><span style="display:flex;"><span>k delete pod kube-proxy-f2l2m -n kube-system 
</span></span><span style="display:flex;"><span>sh /opt/course/15/cluster_events.sh &gt; /opt/course/15/pod_kill.log
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ssh cluster2-nod
</span></span><span style="display:flex;"><span><span style="color:#75715e"># crictl</span>
</span></span><span style="display:flex;"><span>crictl ps | grep kube-proxy
</span></span><span style="display:flex;"><span>crictl rm 1e020b43c4423
</span></span><span style="display:flex;"><span>sh /opt/course/15/cluster_events.sh
</span></span></code></pre></div><h3 id="answer-14">Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/15/cluster_events.sh</span>
</span></span><span style="display:flex;"><span>kubectl get events -A --sort-by<span style="color:#f92672">=</span>.metadata.creationTimestamp
</span></span></code></pre></div><p>Now we delete the kube-proxy <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n kube-system get pod -o wide | grep proxy <span style="color:#75715e"># find pod running on cluster2-node1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k -n kube-system delete pod kube-proxy-z64cg
</span></span></code></pre></div><p>Now check the events:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sh /opt/course/15/cluster_events.sh
</span></span></code></pre></div><p>Write the events the killing caused into <code>/opt/course/15/pod_kill.log</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/15/pod_kill.log</span>
</span></span><span style="display:flex;"><span>kube-system   9s          Normal    Killing           pod/kube-proxy-jsv7t   ...
</span></span><span style="display:flex;"><span>kube-system   3s          Normal    SuccessfulCreate  daemonset/kube-proxy   ...
</span></span><span style="display:flex;"><span>kube-system   &lt;unknown&gt;   Normal    Scheduled         pod/kube-proxy-m52sx   ...
</span></span><span style="display:flex;"><span>default       2s          Normal    Starting          node/cluster2-node1  ...
</span></span><span style="display:flex;"><span>kube-system   2s          Normal    Created           pod/kube-proxy-m52sx   ...
</span></span><span style="display:flex;"><span>kube-system   2s          Normal    Pulled            pod/kube-proxy-m52sx   ...
</span></span><span style="display:flex;"><span>kube-system   2s          Normal    Started           pod/kube-proxy-m52sx   ...
</span></span></code></pre></div><p>Finally we will try to provoke events by killing the container belonging to the container of the kube-proxy <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-node1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# crictl ps | grep kube-proxy
</span></span><span style="display:flex;"><span>1e020b43c4423   36c4ebbc9d979   About an hour ago   Running   kube-proxy     ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# crictl rm 1e020b43c4423
</span></span><span style="display:flex;"><span>1e020b43c4423
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# crictl ps | grep kube-proxy
</span></span><span style="display:flex;"><span>0ae4245707910   36c4ebbc9d979   <span style="color:#ae81ff">17</span> seconds ago      Running   kube-proxy     ...     
</span></span></code></pre></div><p>We killed the main container (1e020b43c4423), but also noticed that a new container (0ae4245707910) was directly created. Thanks Kubernetes!</p>
<p>Now we see if this caused events again and we write those into the second file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sh /opt/course/15/cluster_events.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/15/container_kill.log</span>
</span></span><span style="display:flex;"><span>kube-system   13s         Normal    Created      pod/kube-proxy-m52sx    ...
</span></span><span style="display:flex;"><span>kube-system   13s         Normal    Pulled       pod/kube-proxy-m52sx    ...
</span></span><span style="display:flex;"><span>kube-system   13s         Normal    Started      pod/kube-proxy-m52sx    ...
</span></span></code></pre></div><p>Comparing the events we see that when we deleted the whole <em>Pod</em> there were more things to be done, hence more events. For example was the <em>DaemonSet</em> in the game to re-create the missing <em>Pod</em>. Where when we manually killed the main container of the <em>Pod</em>, the <em>Pod</em> would still exist but only its container needed to be re-created, hence less events.</p>
<h2 id="question-16--namespaces-and-api-resources">Question 16 | Namespaces and Api Resources</h2>
<h3 id="question-15">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Write the names of all namespaced Kubernetes resources (like <em>Pod</em>, <em>Secret</em>, <em>ConfigMap</em>&hellip;) into <code>/opt/course/16/resources.txt</code>.</p>
<p>Find the <code>project-*</code> <em>Namespace</em> with the highest number of <code>Roles</code> defined in it and write its name and amount of <em>Roles</em> into <code>/opt/course/16/crowded-namespace.txt</code>.</p>
<h3 id="my-answer-11">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kc api-resources --namespaced<span style="color:#f92672">=</span>true -o name &gt; /opt/course/16/resources.txt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kc get role -n <span style="color:#f92672">{</span>project-*<span style="color:#f92672">}</span> <span style="color:#75715e"># so many output, no idea.</span>
</span></span></code></pre></div><h3 id="answer-15">Answer</h3>
<p><strong>Namespace and Namespaces Resources</strong></p>
<p>Now we can get a list of all resources like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k api-resources    <span style="color:#75715e"># shows all</span>
</span></span><span style="display:flex;"><span>k api-resources -h <span style="color:#75715e"># help always good</span>
</span></span><span style="display:flex;"><span>k api-resources --namespaced -o name &gt; /opt/course/16/resources.txt
</span></span></code></pre></div><p>Which results in the file:</p>
<pre tabindex="0"><code># /opt/course/16/resources.txt
bindings
configmaps
endpoints
events
limitranges
persistentvolumeclaims
pods
podtemplates
replicationcontrollers
resourcequotas
secrets
serviceaccounts
services
controllerrevisions.apps
daemonsets.apps
deployments.apps
replicasets.apps
statefulsets.apps
localsubjectaccessreviews.authorization.k8s.io
horizontalpodautoscalers.autoscaling
cronjobs.batch
jobs.batch
leases.coordination.k8s.io
events.events.k8s.io
ingresses.extensions
ingresses.networking.k8s.io
networkpolicies.networking.k8s.io
poddisruptionbudgets.policy
rolebindings.rbac.authorization.k8s.io
roles.rbac.authorization.k8s.io
</code></pre><p><strong>Namespace with most Roles</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 get role --no-headers | wc -l
</span></span><span style="display:flex;"><span>No resources found in project-c13 namespace.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-c14 get role --no-headers | wc -l
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">300</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-hamster get role --no-headers | wc -l
</span></span><span style="display:flex;"><span>No resources found in project-hamster namespace.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake get role --no-headers | wc -l
</span></span><span style="display:flex;"><span>No resources found in project-snake namespace.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-tiger get role --no-headers | wc -l
</span></span><span style="display:flex;"><span>No resources found in project-tiger namespace.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>Finally we write the name and amount into the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/16/crowded-namespace.txt</span>
</span></span><span style="display:flex;"><span>project-c14 with <span style="color:#ae81ff">300</span> resources
</span></span></code></pre></div><h2 id="question-17--find-container-of-pod-and-check-info">Question 17 | Find Container of Pod and check info</h2>
<h3 id="question-16">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>In <em>Namespace</em> <code>project-tiger</code> create a <em>Pod</em> named <code>tigers-reunite</code> of image <code>httpd:2.4.41-alpine</code> with labels <code>pod=container</code> and <code>container=pod</code>. Find out on which node the <em>Pod</em> is scheduled. Ssh into that node and find the containerd container belonging to that <em>Pod</em>.</p>
<p>Using command <code>crictl</code>:</p>
<ol>
<li>Write the ID of the container and the <code>info.runtimeType</code> into <code>/opt/course/17/pod-container.txt</code></li>
<li>Write the logs of the container into <code>/opt/course/17/pod-container.log</code></li>
</ol>
<h3 id="my-answer-12">My Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kc run tigers-reunite -n project-tiger --image<span style="color:#f92672">=</span>httpd:2.4.41-alpine
</span></span><span style="display:flex;"><span>kc label pod tigers-reunite pod<span style="color:#f92672">=</span>container -n project-tiger
</span></span><span style="display:flex;"><span>kc label pod tigers-reunite container<span style="color:#f92672">=</span>pod -n project-tiger
</span></span><span style="display:flex;"><span>kc get pod tigers-reunite -n project-tiger -o wide
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ssh cluster1-node2
</span></span><span style="display:flex;"><span>crictl ps | grep tigers-reunite
</span></span><span style="display:flex;"><span>crictl inspect b01edbe6f89ed | grep runtimeType
</span></span><span style="display:flex;"><span>crictl logs b01edbe6f89ed
</span></span></code></pre></div><h3 id="answer-16">Answer</h3>
<p>First we create the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-tiger run tigers-reunite <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --image<span style="color:#f92672">=</span>httpd:2.4.41-alpine <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --labels <span style="color:#e6db74">&#34;pod=container,container=pod&#34;</span>
</span></span></code></pre></div><p>Next we find out the node it&rsquo;s scheduled on:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-tiger get pod -o wide
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or fancy:</span>
</span></span><span style="display:flex;"><span>k -n project-tiger get pod tigers-reunite -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.spec.nodeName}&#34;</span>
</span></span></code></pre></div><p>Then we ssh into that node and and check the container info:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-node2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-node2:~# crictl ps | grep tigers-reunite
</span></span><span style="display:flex;"><span>b01edbe6f89ed    54b0995a63052    <span style="color:#ae81ff">5</span> seconds ago    Running        tigers-reunite ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-node2:~# crictl inspect b01edbe6f89ed | grep runtimeType
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;runtimeType&#34;</span>: <span style="color:#e6db74">&#34;io.containerd.runc.v2&#34;</span>,
</span></span></code></pre></div><p>Then we fill the requested file (on the main terminal):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/17/pod-container.txt</span>
</span></span><span style="display:flex;"><span>b01edbe6f89ed io.containerd.runc.v2
</span></span></code></pre></div><p>Finally we write the container logs in the second file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ssh cluster1-node2 <span style="color:#e6db74">&#39;crictl logs b01edbe6f89ed&#39;</span> &amp;&gt; /opt/course/17/pod-container.log
</span></span></code></pre></div><p>The <code>&amp;&gt;</code> in above&rsquo;s command redirects both the standard output and standard error.</p>
<p>You could also simply run <code>crictl logs</code> on the node and copy the content manually, if it&rsquo;s not a lot. The file should look like:</p>
<pre tabindex="0"><code># /opt/course/17/pod-container.log
AH00558: httpd: Could not reliably determine the server&#39;s fully qualified domain name, using 10.44.0.37. Set the &#39;ServerName&#39; directive globally to suppress this message
AH00558: httpd: Could not reliably determine the server&#39;s fully qualified domain name, using 10.44.0.37. Set the &#39;ServerName&#39; directive globally to suppress this message
[Mon Sep 13 13:32:18.555280 2021] [mpm_event:notice] [pid 1:tid 139929534545224] AH00489: Apache/2.4.41 (Unix) configured -- resuming normal operations
[Mon Sep 13 13:32:18.555610 2021] [core:notice] [pid 1:tid 139929534545224] AH00094: Command line: &#39;httpd -D FOREGROUND&#39; 
</code></pre><h2 id="question-18--fix-kubelet">Question 18 | Fix Kubelet</h2>
<h3 id="question-17">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c3-CCC</code></p>
<p>There seems to be an issue with the kubelet not running on <code>cluster3-node1</code>. Fix it and confirm that cluster has node <code>cluster3-node1</code> available in Ready state afterwards. You should be able to schedule a <em>Pod</em> on <code>cluster3-node1</code> afterwards.</p>
<p>Write the reason of the issue into <code>/opt/course/18/reason.txt</code>.</p>
<h3 id="answer-17">Answer</h3>
<p>The procedure on tasks like these should be to check if the kubelet is running, if not start it, then check its logs and correct errors if there are some.</p>
<p>Always helpful to check if other clusters already have some of the components defined and running, so you can copy and use existing config files. Though in this case it might not need to be necessary.</p>
<p>Check node status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS     ROLES           AGE   VERSION
</span></span><span style="display:flex;"><span>cluster3-controlplane1   Ready      control-plane   14d   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node1           NotReady   &lt;none&gt;          14d   v1.29.0
</span></span></code></pre></div><p>First we check if the kubelet is running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-node1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node1:~# ps aux | grep kubelet
</span></span><span style="display:flex;"><span>root     <span style="color:#ae81ff">29294</span>  0.0  0.2  <span style="color:#ae81ff">14856</span>  <span style="color:#ae81ff">1016</span> pts/0    S+   11:30   0:00 grep --color<span style="color:#f92672">=</span>auto kubelet
</span></span></code></pre></div><p>Nope, so we check if it&rsquo;s configured using systemd as service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node1:~# service kubelet status
</span></span><span style="display:flex;"><span>● kubelet.service - kubelet: The Kubernetes Node Agent
</span></span><span style="display:flex;"><span>     Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    Drop-In: /usr/lib/systemd/system/kubelet.service.d
</span></span><span style="display:flex;"><span>             └─10-kubeadm.conf
</span></span><span style="display:flex;"><span>     Active: inactive <span style="color:#f92672">(</span>dead<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>Result: exit-code<span style="color:#f92672">)</span> since Thu 2024-01-04 13:12:54 UTC; 1h 23min ago
</span></span><span style="display:flex;"><span>       Docs: https://kubernetes.io/docs/
</span></span><span style="display:flex;"><span>    Process: <span style="color:#ae81ff">27577</span> ExecStart<span style="color:#f92672">=</span>/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>&gt;
</span></span><span style="display:flex;"><span>   Main PID: <span style="color:#ae81ff">27577</span> <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>203/EXEC<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 13:12:52 cluster3-node1 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Main process exited, code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>203/EXEC
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 13:12:52 cluster3-node1 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Failed with result <span style="color:#e6db74">&#39;exit-code&#39;</span>.
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 13:12:54 cluster3-node1 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: Stopped kubelet: The Kubernetes Node Agent.
</span></span></code></pre></div><p>Yes, it&rsquo;s configured as a service with config at <code>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</code>, but we see it&rsquo;s inactive. Let&rsquo;s try to start it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node1:~# service kubelet start
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node1:~# service kubelet status
</span></span><span style="display:flex;"><span>● kubelet.service - kubelet: The Kubernetes Node Agent
</span></span><span style="display:flex;"><span>     Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    Drop-In: /usr/lib/systemd/system/kubelet.service.d
</span></span><span style="display:flex;"><span>             └─10-kubeadm.conf
</span></span><span style="display:flex;"><span>     Active: activating <span style="color:#f92672">(</span>auto-restart<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>Result: exit-code<span style="color:#f92672">)</span> since Thu 2024-01-04 14:37:02 UTC; 6s ago
</span></span><span style="display:flex;"><span>       Docs: https://kubernetes.io/docs/
</span></span><span style="display:flex;"><span>    Process: <span style="color:#ae81ff">27935</span> ExecStart<span style="color:#f92672">=</span>/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>&gt;
</span></span><span style="display:flex;"><span>   Main PID: <span style="color:#ae81ff">27935</span> <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>203/EXEC<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 14:37:02 cluster3-node1 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Main process exited, code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>203/EXEC
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 14:37:02 cluster3-node1 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Failed with result <span style="color:#e6db74">&#39;exit-code&#39;</span>.
</span></span></code></pre></div><p>We see it&rsquo;s trying to execute <code>/usr/local/bin/kubelet</code> with some parameters defined in its service config file. A good way to find errors and get more logs is to run the command manually (usually also with its parameters).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node1:~# /usr/local/bin/kubelet
</span></span><span style="display:flex;"><span>-bash: /usr/local/bin/kubelet: No such file or directory
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node1:~# whereis kubelet
</span></span><span style="display:flex;"><span>kubelet: /usr/bin/kubelet
</span></span></code></pre></div><p>Another way would be to see the extended logging of a service like using <code>journalctl -u kubelet</code>.</p>
<p><strong>Well, there we have it, wrong path specified. Correct the path in file</strong> <code>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</code> and run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf <span style="color:#75715e"># fix binary path</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl daemon-reload
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>service kubelet restart
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>service kubelet status  <span style="color:#75715e"># should now show running</span>
</span></span></code></pre></div><p>Also the node should be available for the api server, <strong>give it a bit of time though</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE   VERSION
</span></span><span style="display:flex;"><span>cluster3-controlplane1   Ready    control-plane   14d   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node1           Ready    &lt;none&gt;          14d   v1.29.0
</span></span></code></pre></div><p>Finally we write the reason into the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/18/reason.txt</span>
</span></span><span style="display:flex;"><span>wrong path to kubelet binary specified in service config
</span></span></code></pre></div><h2 id="question-19--create-secret-and-mount-into-pod">Question 19 | Create Secret and mount into Pod</h2>
<h3 id="question-18">Question</h3>
<blockquote>
<p><strong>NOTE:</strong> This task can only be solved if questions 18 or 20 have been successfully implemented and the k8s-c3-CCC cluster has a functioning worker node</p>
</blockquote>
<p>Use context: <code>kubectl config use-context k8s-c3-CCC</code></p>
<p>Do the following in a new <em>Namespace</em> <code>secret</code>. Create a <em>Pod</em> named <code>secret-pod</code> of image <code>busybox:1.31.1</code> which should keep running for some time.</p>
<p>There is an existing <em>Secret</em> located at <code>/opt/course/19/secret1.yaml</code>, create it in the <em>Namespace</em> <code>secret</code> and mount it readonly into the <em>Pod</em> at <code>/tmp/secret1</code>.</p>
<p>Create a new <em>Secret</em> in <em>Namespace</em> <code>secret</code> called <code>secret2</code> which should contain <code>user=user1</code> and <code>pass=1234</code>. These entries should be available inside the <em>Pod&rsquo;s</em> container as environment variables <code>APP_USER</code> and <code>APP_PASS</code>.</p>
<p>Confirm everything is working.</p>
<h3 id="ref-3">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/inject-data-application/distribute-credentials-secure/">https://kubernetes.io/zh-cn/docs/tasks/inject-data-application/distribute-credentials-secure/</a></p>
<h3 id="answer-18">Answer</h3>
<p>First we create the <em>Namespace</em> and the requested <em>Secrets</em> in it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k create ns secret
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp /opt/course/19/secret1.yaml 19_secret1.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 19_secret1.yaml
</span></span></code></pre></div><p>We need to adjust the <em>Namespace</em> for that <em>Secret</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 19_secret1.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">halt</span>: <span style="color:#ae81ff">IyEgL2Jpbi9zaAo...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">secret          </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">k -f 19_secret1.yaml create</span>
</span></span></code></pre></div><p>Next we create the second <em>Secret</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n secret create secret generic secret2 --from-literal<span style="color:#f92672">=</span>user<span style="color:#f92672">=</span>user1 --from-literal<span style="color:#f92672">=</span>pass<span style="color:#f92672">=</span><span style="color:#ae81ff">1234</span>
</span></span></code></pre></div><p>Now we create the <em>Pod</em> template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n secret run secret-pod --image<span style="color:#f92672">=</span>busybox:1.31.1 $do -- sh -c <span style="color:#e6db74">&#34;sleep 5d&#34;</span> &gt; 19.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim 19.yaml
</span></span></code></pre></div><p>Then make the necessary changes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 19.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">secret-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">secret                      </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sh</span>
</span></span><span style="display:flex;"><span>    - -<span style="color:#ae81ff">c</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sleep 1d</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31.1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>:                                  <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">APP_USER                     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:                          <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">secretKeyRef</span>:                     <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret2                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">key</span>: <span style="color:#ae81ff">user                      </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">APP_PASS                     </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:                          <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">secretKeyRef</span>:                     <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret2                  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">key</span>: <span style="color:#ae81ff">pass                      </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:                         <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret1                      </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/tmp/secret1            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>                      <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:                                <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">secret1                        </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secret</span>:                               <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">secret1                </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>It might not be necessary in current K8s versions to specify the <code>readOnly: true</code> because it&rsquo;s the <a href="https://github.com/kubernetes/kubernetes/issues/62099">default setting anyways</a>.</p>
<p>And execute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 19.yaml create
</span></span></code></pre></div><p>Finally we check if all is correct:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n secret exec secret-pod -- env | grep APP
</span></span><span style="display:flex;"><span>APP_PASS<span style="color:#f92672">=</span><span style="color:#ae81ff">1234</span>
</span></span><span style="display:flex;"><span>APP_USER<span style="color:#f92672">=</span>user1
</span></span><span style="display:flex;"><span>➜ k -n secret exec secret-pod -- find /tmp/secret1
</span></span><span style="display:flex;"><span>/tmp/secret1
</span></span><span style="display:flex;"><span>/tmp/secret1/..data
</span></span><span style="display:flex;"><span>/tmp/secret1/halt
</span></span><span style="display:flex;"><span>/tmp/secret1/..2019_12_08_12_15_39.463036797
</span></span><span style="display:flex;"><span>/tmp/secret1/..2019_12_08_12_15_39.463036797/halt
</span></span><span style="display:flex;"><span>➜ k -n secret exec secret-pod -- cat /tmp/secret1/halt
</span></span><span style="display:flex;"><span><span style="color:#75715e">#! /bin/sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### BEGIN INIT INFO</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Provides:          halt</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Required-Start:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Required-Stop:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Default-Start:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Default-Stop:      0</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Short-Description: Execute the halt command.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Description:</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>All is good.</p>
<h2 id="question-20--update-kubernetes-version-and-join-cluster">Question 20 | Update Kubernetes Version and join cluster</h2>
<h3 id="question-19">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c3-CCC</code></p>
<p>Your coworker said node <code>cluster3-node2</code> is running an older Kubernetes version and is not even part of the cluster. Update Kubernetes on that node to the exact version that&rsquo;s running on <code>cluster3-controlplane1</code>. Then add this node to the cluster. Use kubeadm for this.</p>
<h3 id="ref-4">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/</a></p>
<p><a href="https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/">https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/</a></p>
<h3 id="answer-19">Answer</h3>
<h4 id="upgrade-kubernetes-to-cluster3-controlplane1-version">Upgrade Kubernetes to cluster3-controlplane1 version</h4>
<p>Search in the docs for kubeadm upgrade: <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>cluster3-controlplane1   Ready    control-plane   3h28m   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node1           Ready    &lt;none&gt;          3h23m   v1.29.0
</span></span></code></pre></div><p>Controlplane node seems to be running Kubernetes 1.29.0. Node <code>cluster3-node1</code> might not yet be part of the cluster depending on the completion of a previous task.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-node2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubectl version --short
</span></span><span style="display:flex;"><span>Client Version: v1.28.5
</span></span><span style="display:flex;"><span>Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
</span></span><span style="display:flex;"><span>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubelet --version
</span></span><span style="display:flex;"><span>Kubernetes v1.28.5
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubeadm version
</span></span><span style="display:flex;"><span>kubeadm version: &amp;version.Info<span style="color:#f92672">{</span>Major:<span style="color:#e6db74">&#34;1&#34;</span>, Minor:<span style="color:#e6db74">&#34;29&#34;</span>, GitVersion:<span style="color:#e6db74">&#34;v1.29.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;3f7a50f38688eb332e2a1b013678c6435d539ae6&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span>, BuildDate:<span style="color:#e6db74">&#34;2023-12-13T08:50:10Z&#34;</span>, GoVersion:<span style="color:#e6db74">&#34;go1.21.5&#34;</span>, Compiler:<span style="color:#e6db74">&#34;gc&#34;</span>, Platform:<span style="color:#e6db74">&#34;linux/amd64&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>Above we can see that kubeadm is already installed in the wanted version, so we don&rsquo;t need to install it. Hence we can run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubeadm upgrade node
</span></span><span style="display:flex;"><span>couldn<span style="color:#960050;background-color:#1e0010">&#39;</span>t create a Kubernetes client from file <span style="color:#e6db74">&#34;/etc/kubernetes/kubelet.conf&#34;</span>: failed to load admin kubeconfig: open /etc/kubernetes/kubelet.conf: no such file or directory
</span></span><span style="display:flex;"><span>To see the stack trace of this error execute with --v<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span> or higher
</span></span></code></pre></div><p>This is usually the proper command to upgrade a node. But this error means that this node was never even initialised, so nothing to update here. This will be done later using <code>kubeadm join</code>. For now we can continue with kubelet and kubectl:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node2:~# apt update
</span></span><span style="display:flex;"><span>Hit:1 http://ppa.launchpad.net/rmescandon/yq/ubuntu focal InRelease
</span></span><span style="display:flex;"><span>Hit:3 http://us.archive.ubuntu.com/ubuntu focal InRelease                                                                                             
</span></span><span style="display:flex;"><span>Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease    
</span></span><span style="display:flex;"><span>Hit:2 https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.28/deb  InRelease
</span></span><span style="display:flex;"><span>Hit:5 https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.29/deb  InRelease
</span></span><span style="display:flex;"><span>Get:6 http://us.archive.ubuntu.com/ubuntu focal-updates InRelease <span style="color:#f92672">[</span><span style="color:#ae81ff">114</span> kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Hit:7 http://us.archive.ubuntu.com/ubuntu focal-backports InRelease
</span></span><span style="display:flex;"><span>Get:8 http://us.archive.ubuntu.com/ubuntu focal-updates/main i386 Packages <span style="color:#f92672">[</span><span style="color:#ae81ff">919</span> kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Get:9 http://us.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages <span style="color:#f92672">[</span>3,023 kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Get:10 http://us.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages <span style="color:#f92672">[</span>1,141 kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Get:11 http://us.archive.ubuntu.com/ubuntu focal-updates/universe i386 Packages <span style="color:#f92672">[</span><span style="color:#ae81ff">762</span> kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Fetched 5,959 kB in 3s <span style="color:#f92672">(</span>2,049 kB/s<span style="color:#f92672">)</span>                   
</span></span><span style="display:flex;"><span>Reading package lists... Done
</span></span><span style="display:flex;"><span>Building dependency tree       
</span></span><span style="display:flex;"><span>Reading state information... Done
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">222</span> packages can be upgraded. Run <span style="color:#e6db74">&#39;apt list --upgradable&#39;</span> to see them.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# apt show kubectl -a | grep 1.29
</span></span><span style="display:flex;"><span>Version: 1.29.0-1.1
</span></span><span style="display:flex;"><span>APT-Sources: https://pkgs.k8s.io/core:/stable:/v1.29/deb  Packages
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# apt install kubectl<span style="color:#f92672">=</span>1.29.0-1.1 kubelet<span style="color:#f92672">=</span>1.29.0-1.1
</span></span><span style="display:flex;"><span>Reading package lists... Done
</span></span><span style="display:flex;"><span>Building dependency tree       
</span></span><span style="display:flex;"><span>Reading state information... Done
</span></span><span style="display:flex;"><span>The following packages will be upgraded:
</span></span><span style="display:flex;"><span>  kubectl kubelet
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> upgraded, <span style="color:#ae81ff">0</span> newly installed, <span style="color:#ae81ff">0</span> to remove and <span style="color:#ae81ff">220</span> not upgraded.
</span></span><span style="display:flex;"><span>Need to get 30.3 MB of archives.
</span></span><span style="display:flex;"><span>After this operation, <span style="color:#ae81ff">782</span> kB of additional disk space will be used.
</span></span><span style="display:flex;"><span>Get:1 https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.29/deb  kubectl 1.29.0-1.1 <span style="color:#f92672">[</span>10.5 MB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Get:2 https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.29/deb  kubelet 1.29.0-1.1 <span style="color:#f92672">[</span>19.8 MB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Fetched 30.3 MB in 1s <span style="color:#f92672">(</span>40.8 MB/s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>Reading database ... <span style="color:#ae81ff">112588</span> files and directories currently installed.<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Preparing to unpack .../kubectl_1.29.0-1.1_amd64.deb ...
</span></span><span style="display:flex;"><span>Unpacking kubectl <span style="color:#f92672">(</span>1.29.0-1.1<span style="color:#f92672">)</span> over <span style="color:#f92672">(</span>1.28.5-1.1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>Preparing to unpack .../kubelet_1.29.0-1.1_amd64.deb ...
</span></span><span style="display:flex;"><span>Unpacking kubelet <span style="color:#f92672">(</span>1.29.0-1.1<span style="color:#f92672">)</span> over <span style="color:#f92672">(</span>1.28.5-1.1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>Setting up kubectl <span style="color:#f92672">(</span>1.29.0-1.1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>Setting up kubelet <span style="color:#f92672">(</span>1.29.0-1.1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubelet --version
</span></span><span style="display:flex;"><span>Kubernetes v1.29.0
</span></span></code></pre></div><p>Now we&rsquo;re up to date with kubeadm, kubectl and kubelet. Restart the kubelet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-node2:~# service kubelet restart
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# service kubelet status
</span></span><span style="display:flex;"><span>● kubelet.service - kubelet: The Kubernetes Node Agent
</span></span><span style="display:flex;"><span>     Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    Drop-In: /usr/lib/systemd/system/kubelet.service.d
</span></span><span style="display:flex;"><span>             └─10-kubeadm.conf
</span></span><span style="display:flex;"><span>     Active: activating <span style="color:#f92672">(</span>auto-restart<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>Result: exit-code<span style="color:#f92672">)</span> since Thu 2024-01-04 14:01:11 UTC; 2s ago
</span></span><span style="display:flex;"><span>       Docs: https://kubernetes.io/docs/
</span></span><span style="display:flex;"><span>    Process: <span style="color:#ae81ff">43818</span> ExecStart<span style="color:#f92672">=</span>/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>1/FAIL&gt;
</span></span><span style="display:flex;"><span>   Main PID: <span style="color:#ae81ff">43818</span> <span style="color:#f92672">(</span>code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>1/FAILURE<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 14:01:11 cluster3-node2 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Main process exited, code<span style="color:#f92672">=</span>exited, status<span style="color:#f92672">=</span>1/FAILURE
</span></span><span style="display:flex;"><span>Jan <span style="color:#ae81ff">04</span> 14:01:11 cluster3-node2 systemd<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>: kubelet.service: Failed with result <span style="color:#e6db74">&#39;exit-code&#39;</span>.
</span></span></code></pre></div><p>These errors occur because we still need to run <code>kubeadm join</code> to join the node into the cluster. Let&rsquo;s do this in the next step.</p>
<h4 id="add-cluster3-node2-to-cluster">Add cluster3-node2 to cluster</h4>
<p>First we log into the controlplane1 and generate a new TLS bootstrap token, also printing out the join command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# kubeadm token create --print-join-command
</span></span><span style="display:flex;"><span>kubeadm join 192.168.100.31:6443 --token pbuqzw.83kz9uju8talblrl --discovery-token-ca-cert-hash sha256:eae975465f73f316f322bcdd5eb6a5a53f08662ecb407586561cdc06f74bf7b2 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# kubeadm token list
</span></span><span style="display:flex;"><span>TOKEN                     TTL         EXPIRES                ...
</span></span><span style="display:flex;"><span>dm3ws5.hga8xkwpp0f2lk4q   20h         2024-01-05T10:28:19Z
</span></span><span style="display:flex;"><span>pbuqzw.83kz9uju8talblrl   23h         2024-01-05T14:01:38Z
</span></span><span style="display:flex;"><span>rhjon6.qra3to1sjf2xnn0l   &lt;forever&gt;   &lt;never&gt;
</span></span></code></pre></div><p>We see the expiration of 23h for our token, we could adjust this by passing the ttl argument.</p>
<p>Next we connect again to <code>cluster3-node2</code> and simply execute the join command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-node2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# kubeadm join 192.168.100.31:6443 --token pbuqzw.83kz9uju8talblrl --discovery-token-ca-cert-hash sha256:eae975465f73f316f322bcdd5eb6a5a53f08662ecb407586561cdc06f74bf7b2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> Running pre-flight checks
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> Reading configuration from the cluster...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> FYI: You can look at this config file with <span style="color:#e6db74">&#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Writing kubelet configuration to file <span style="color:#e6db74">&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Writing kubelet environment file with flags to file <span style="color:#e6db74">&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Starting the kubelet
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Waiting <span style="color:#66d9ef">for</span> the kubelet to perform the TLS Bootstrap...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This node has joined the cluster:
</span></span><span style="display:flex;"><span>* Certificate signing request was sent to apiserver and a response was received.
</span></span><span style="display:flex;"><span>* The Kubelet was informed of the new secure connection details.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Run <span style="color:#e6db74">&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-node2:~# service kubelet status
</span></span><span style="display:flex;"><span>● kubelet.service - kubelet: The Kubernetes Node Agent
</span></span><span style="display:flex;"><span>     Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    Drop-In: /usr/lib/systemd/system/kubelet.service.d
</span></span><span style="display:flex;"><span>             └─10-kubeadm.conf
</span></span><span style="display:flex;"><span>     Active: active <span style="color:#f92672">(</span>running<span style="color:#f92672">)</span> since Thu 2024-01-04 14:02:45 UTC; 13s ago
</span></span><span style="display:flex;"><span>       Docs: https://kubernetes.io/docs/
</span></span><span style="display:flex;"><span>   Main PID: <span style="color:#ae81ff">44103</span> <span style="color:#f92672">(</span>kubelet<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      Tasks: <span style="color:#ae81ff">10</span> <span style="color:#f92672">(</span>limit: 462<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>     Memory: 55.5M
</span></span><span style="display:flex;"><span>     CGroup: /system.slice/kubelet.service
</span></span><span style="display:flex;"><span>             └─44103 /usr/bin/kubelet --bootstrap-kubeconfig<span style="color:#f92672">=</span>/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig<span style="color:#f92672">=</span>/etc/kubernetes/kubelet.conf --config<span style="color:#f92672">=</span>/var/lib/k&gt;
</span></span></code></pre></div><p>If you have troubles with <code>kubeadm join</code> you might need to run <code>kubeadm reset</code>.</p>
<p>This looks great though for us. Finally we head back to the main terminal and check the node status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS     ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>cluster3-controlplane1   Ready      control-plane   3h34m   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node1           Ready      &lt;none&gt;          3h29m   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node2           NotReady   &lt;none&gt;          20s     v1.29.0
</span></span></code></pre></div><p>Give it a bit of time till the node is ready.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>cluster3-controlplane1   Ready    control-plane   3h34m   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node1           Ready    &lt;none&gt;          3h29m   v1.29.0
</span></span><span style="display:flex;"><span>cluster3-node2           Ready    &lt;none&gt;          27s     v1.29.0
</span></span></code></pre></div><p>We see <code>cluster3-node2</code> is now available and up to date.</p>
<h2 id="question-21--create-a-static-pod-and-service">Question 21 | Create a Static Pod and Service</h2>
<h3 id="question-20">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c3-CCC</code></p>
<p>Create a <code>Static Pod</code> named <code>my-static-pod</code> in <em>Namespace</em> <code>default</code> on <code>cluster3-controlplane1</code>. It should be of image <code>nginx:1.16-alpine</code> and have resource requests for <code>10m</code> CPU and <code>20Mi</code> memory.</p>
<p>Then create a NodePort <em>Service</em> named <code>static-pod-service</code> which exposes that static <em>Pod</em> on port 80 and check if it has <em>Endpoints</em> and if it&rsquo;s reachable through the <code>cluster3-controlplane1</code> internal IP address. You can connect to the internal node IPs from your main terminal.</p>
<h3 id="ref-5">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/static-pod/">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/static-pod/</a></p>
<h3 id="answer-20">Answer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# cd /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1:~# kubectl run my-static-pod <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --image<span style="color:#f92672">=</span>nginx:1.16-alpine <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -o yaml --dry-run<span style="color:#f92672">=</span>client &gt; my-static-pod.yaml
</span></span></code></pre></div><p>Then edit the <code>my-static-pod.yaml</code> to add the requested resource requests:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/manifests/my-static-pod.yaml</span>
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  creationTimestamp: null
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    run: my-static-pod
</span></span><span style="display:flex;"><span>  name: my-static-pod
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - image: nginx:1.16-alpine
</span></span><span style="display:flex;"><span>    name: my-static-pod
</span></span><span style="display:flex;"><span>    resources:
</span></span><span style="display:flex;"><span>      requests:
</span></span><span style="display:flex;"><span>        cpu: 10m
</span></span><span style="display:flex;"><span>        memory: 20Mi
</span></span><span style="display:flex;"><span>  dnsPolicy: ClusterFirst
</span></span><span style="display:flex;"><span>  restartPolicy: Always
</span></span><span style="display:flex;"><span>status: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><p>And make sure it&rsquo;s running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod -A | grep my-static
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                                   READY   STATUS   ...   AGE
</span></span><span style="display:flex;"><span>default       my-static-pod-cluster3-controlplane1   1/1     Running  ...   22s
</span></span></code></pre></div><p>Now we expose that static <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k expose pod my-static-pod-cluster3-controlplane1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name static-pod-service <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --type<span style="color:#f92672">=</span>NodePort <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --port <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>This would generate a <em>Service</em> like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># kubectl expose pod my-static-pod-cluster3-controlplane1 --name static-pod-service --type=NodePort --port 80</span>
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Service
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  creationTimestamp: null
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    run: my-static-pod
</span></span><span style="display:flex;"><span>  name: static-pod-service
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  ports:
</span></span><span style="display:flex;"><span>  - port: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    protocol: TCP
</span></span><span style="display:flex;"><span>    targetPort: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  selector:
</span></span><span style="display:flex;"><span>    run: my-static-pod
</span></span><span style="display:flex;"><span>  type: NodePort
</span></span><span style="display:flex;"><span>status:
</span></span><span style="display:flex;"><span>  loadBalancer: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><p>Then run and test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get svc,ep -l run<span style="color:#f92672">=</span>my-static-pod
</span></span><span style="display:flex;"><span>NAME                         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE
</span></span><span style="display:flex;"><span>service/static-pod-service   NodePort   10.99.168.252   &lt;none&gt;        80:30352/TCP   30s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                           ENDPOINTS      AGE
</span></span><span style="display:flex;"><span>endpoints/static-pod-service   10.32.0.4:80   30s
</span></span></code></pre></div><p>Looking good.</p>
<h2 id="question-22--check-how-long-certificates-are-valid">Question 22 | Check how long certificates are valid</h2>
<h3 id="question-21">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>Check how long the kube-apiserver server certificate is valid on <code>cluster2-controlplane1</code>. Do this with openssl or cfssl. Write the exipiration date into <code>/opt/course/22/expiration</code>.</p>
<p>Also run the correct <code>kubeadm</code> command to list the expiration dates and confirm both methods show the same date.</p>
<p>Write the correct <code>kubeadm</code> command that would renew the apiserver server certificate into <code>/opt/course/22/kubeadm-renew-certs.sh</code>.</p>
<h3 id="answer-21">Answer</h3>
<p>First let&rsquo;s find that certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# find /etc/kubernetes/pki | grep apiserver
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver.crt
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver-etcd-client.crt
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver-etcd-client.key
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver-kubelet-client.crt
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver.key
</span></span><span style="display:flex;"><span>/etc/kubernetes/pki/apiserver-kubelet-client.key
</span></span></code></pre></div><p>Next we use openssl to find out the expiration date:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# openssl x509  -noout -text -in /etc/kubernetes/pki/apiserver.crt | grep Validity -A2
</span></span><span style="display:flex;"><span>        Validity
</span></span><span style="display:flex;"><span>            Not Before: Dec <span style="color:#ae81ff">20</span> 18:05:20 <span style="color:#ae81ff">2022</span> GMT
</span></span><span style="display:flex;"><span>            Not After : Dec <span style="color:#ae81ff">20</span> 18:05:20 <span style="color:#ae81ff">2023</span> GMT
</span></span></code></pre></div><p>There we have it, so we write it in the required location on our main terminal:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/22/expiration</span>
</span></span><span style="display:flex;"><span>Dec <span style="color:#ae81ff">20</span> 18:05:20 <span style="color:#ae81ff">2023</span> GMT
</span></span></code></pre></div><p>And we use the feature from kubeadm to get the expiration too:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubeadm certs check-expiration | grep apiserver
</span></span><span style="display:flex;"><span>apiserver                Jan 14, <span style="color:#ae81ff">2022</span> 18:49 UTC   363d        ca               no      
</span></span><span style="display:flex;"><span>apiserver-etcd-client    Jan 14, <span style="color:#ae81ff">2022</span> 18:49 UTC   363d        etcd-ca          no      
</span></span><span style="display:flex;"><span>apiserver-kubelet-client Jan 14, <span style="color:#ae81ff">2022</span> 18:49 UTC   363d        ca               no 
</span></span></code></pre></div><p>Looking good. And finally we write the command that would renew all certificates into the requested location:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/22/kubeadm-renew-certs.sh</span>
</span></span><span style="display:flex;"><span>kubeadm certs renew apiserver
</span></span></code></pre></div><h2 id="question-23--kubelet-clientserver-cert-info">Question 23 | Kubelet client/server cert info</h2>
<h3 id="question-22">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>Node <code>cluster2-node1</code> has been added to the cluster using <code>kubeadm</code> and TLS bootstrapping.</p>
<p>Find the &ldquo;Issuer&rdquo; and &ldquo;Extended Key Usage&rdquo; values of the <code>cluster2-node1</code>:</p>
<ol>
<li>kubelet <strong>client</strong> certificate, the one used for outgoing connections to the kube-apiserver.</li>
<li>kubelet <strong>server</strong> certificate, the one used for incoming connections from the kube-apiserver.</li>
</ol>
<p>Write the information into file <code>/opt/course/23/certificate-info.txt</code>.</p>
<p>Compare the &ldquo;Issuer&rdquo; and &ldquo;Extended Key Usage&rdquo; fields of both certificates and make sense of these.</p>
<h3 id="answer-22">Answer</h3>
<p>To find the correct kubelet certificate directory, we can look for the default value of the <code>--cert-dir</code> parameter for the kubelet. For this search for &ldquo;kubelet&rdquo; in the Kubernetes docs which will lead to: <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet</a>. We can check if another certificate directory has been configured using <code>ps aux</code> or in <code>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</code>.</p>
<p>First we check the kubelet client certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-node1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# openssl x509  -noout -text -in /var/lib/kubelet/pki/kubelet-client-current.pem | grep Issuer
</span></span><span style="display:flex;"><span>        Issuer: CN <span style="color:#f92672">=</span> kubernetes
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# openssl x509  -noout -text -in /var/lib/kubelet/pki/kubelet-client-current.pem | grep <span style="color:#e6db74">&#34;Extended Key Usage&#34;</span> -A1
</span></span><span style="display:flex;"><span>            X509v3 Extended Key Usage: 
</span></span><span style="display:flex;"><span>                TLS Web Client Authentication
</span></span></code></pre></div><p>Next we check the kubelet server certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-node1:~# openssl x509  -noout -text -in /var/lib/kubelet/pki/kubelet.crt | grep Issuer
</span></span><span style="display:flex;"><span>          Issuer: CN <span style="color:#f92672">=</span> cluster2-node1-ca@1588186506
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-node1:~# openssl x509  -noout -text -in /var/lib/kubelet/pki/kubelet.crt | grep <span style="color:#e6db74">&#34;Extended Key Usage&#34;</span> -A1
</span></span><span style="display:flex;"><span>            X509v3 Extended Key Usage: 
</span></span><span style="display:flex;"><span>                TLS Web Server Authentication
</span></span></code></pre></div><p>We see that the server certificate was generated on the worker node itself and the client certificate was issued by the Kubernetes api. The &ldquo;Extended Key Usage&rdquo; also shows if it&rsquo;s for client or server authentication.</p>
<p>More about this: <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping</a></p>
<h2 id="question-24--networkpolicy">Question 24 | NetworkPolicy</h2>
<h3 id="question-23">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>There was a security incident where an intruder was able to access the whole cluster from a single hacked backend <em>Pod</em>.</p>
<p>To prevent this create a <em>NetworkPolicy</em> called <code>np-backend</code> in <em>Namespace</em> <code>project-snake</code>. It should allow the <code>backend-*</code> <em>Pods</em> only to:</p>
<ul>
<li>connect to <code>db1-*</code> <em>Pods</em> on port 1111</li>
<li>connect to <code>db2-*</code> <em>Pods</em> on port 2222</li>
</ul>
<p>Use the <code>app</code> label of <em>Pods</em> in your policy.</p>
<p>After implementation, connections from <code>backend-*</code> <em>Pods</em> to <code>vault-*</code> <em>Pods</em> on port 3333 should for example no longer work.</p>
<h3 id="ref-6">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/network-policies/">https://kubernetes.io/zh-cn/docs/concepts/services-networking/network-policies/</a></p>
<h3 id="answer-23">Answer</h3>
<p>First we look at the existing <em>Pods</em> and their labels:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-snake get pod
</span></span><span style="display:flex;"><span>NAME        READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>backend-0   1/1     Running   <span style="color:#ae81ff">0</span>          8s
</span></span><span style="display:flex;"><span>db1-0       1/1     Running   <span style="color:#ae81ff">0</span>          8s
</span></span><span style="display:flex;"><span>db2-0       1/1     Running   <span style="color:#ae81ff">0</span>          10s
</span></span><span style="display:flex;"><span>vault-0     1/1     Running   <span style="color:#ae81ff">0</span>          10s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake get pod -L app
</span></span><span style="display:flex;"><span>NAME        READY   STATUS    RESTARTS   AGE     APP
</span></span><span style="display:flex;"><span>backend-0   1/1     Running   <span style="color:#ae81ff">0</span>          3m15s   backend
</span></span><span style="display:flex;"><span>db1-0       1/1     Running   <span style="color:#ae81ff">0</span>          3m15s   db1
</span></span><span style="display:flex;"><span>db2-0       1/1     Running   <span style="color:#ae81ff">0</span>          3m17s   db2
</span></span><span style="display:flex;"><span>vault-0     1/1     Running   <span style="color:#ae81ff">0</span>          3m17s   vault
</span></span></code></pre></div><p>We test the current connection situation and see nothing is restricted:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-snake get pod -o wide
</span></span><span style="display:flex;"><span>NAME        READY   STATUS    RESTARTS   AGE     IP          ...
</span></span><span style="display:flex;"><span>backend-0   1/1     Running   <span style="color:#ae81ff">0</span>          4m14s   10.44.0.24  ...
</span></span><span style="display:flex;"><span>db1-0       1/1     Running   <span style="color:#ae81ff">0</span>          4m14s   10.44.0.25  ...
</span></span><span style="display:flex;"><span>db2-0       1/1     Running   <span style="color:#ae81ff">0</span>          4m16s   10.44.0.23  ...
</span></span><span style="display:flex;"><span>vault-0     1/1     Running   <span style="color:#ae81ff">0</span>          4m16s   10.44.0.22  ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.25:1111
</span></span><span style="display:flex;"><span>database one
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.23:2222
</span></span><span style="display:flex;"><span>database two
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.22:3333
</span></span><span style="display:flex;"><span>vault secret storage
</span></span></code></pre></div><p>Now we create the <em>NP</em> by copying and chaning an example from the k8s docs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">vim 24_np.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 24_np.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">np-backend</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-snake</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">backend</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">policyTypes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">Egress                   </span> <span style="color:#75715e"># policy is only about Egress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">egress</span>:
</span></span><span style="display:flex;"><span>    -                           <span style="color:#75715e"># first rule</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">to</span>:                           <span style="color:#75715e"># first condition &#34;to&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">app</span>: <span style="color:#ae81ff">db1</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ports</span>:                        <span style="color:#75715e"># second condition &#34;port&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">1111</span>
</span></span><span style="display:flex;"><span>    -                           <span style="color:#75715e"># second rule</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">to</span>:                           <span style="color:#75715e"># first condition &#34;to&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">app</span>: <span style="color:#ae81ff">db2</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ports</span>:                        <span style="color:#75715e"># second condition &#34;port&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">2222</span>
</span></span></code></pre></div><p>The <em>NP</em> above has two rules with two conditions each, it can be read as:</p>
<pre tabindex="0"><code>allow outgoing traffic if:
  (destination pod has label app=db1 AND port is 1111)
  OR
  (destination pod has label app=db2 AND port is 2222)
</code></pre><p><strong>Wrong example</strong></p>
<p>Now let&rsquo;s shortly look at a wrong example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># WRONG</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">np-backend</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-snake</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">backend</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">policyTypes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">Egress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">egress</span>:
</span></span><span style="display:flex;"><span>    -                           <span style="color:#75715e"># first rule</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">to</span>:                           <span style="color:#75715e"># first condition &#34;to&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">podSelector</span>:                    <span style="color:#75715e"># first &#34;to&#34; possibility</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">app</span>: <span style="color:#ae81ff">db1</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">podSelector</span>:                    <span style="color:#75715e"># second &#34;to&#34; possibility</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">app</span>: <span style="color:#ae81ff">db2</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ports</span>:                        <span style="color:#75715e"># second condition &#34;ports&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP                  </span> <span style="color:#75715e"># first &#34;ports&#34; possibility</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">1111</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP                  </span> <span style="color:#75715e"># second &#34;ports&#34; possibility</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">2222</span>
</span></span></code></pre></div><p>The <em>NP</em> above has one rule with two conditions and two condition-entries each, it can be read as:</p>
<pre tabindex="0"><code>allow outgoing traffic if:
  (destination pod has label app=db1 OR destination pod has label app=db2)
  AND
  (destination port is 1111 OR destination port is 2222)
</code></pre><p>Using this <em>NP</em> it would still be possible for <code>backend-*</code> <em>Pods</em> to connect to <code>db2-*</code> <em>Pods</em> on port 1111 for example which should be forbidden.</p>
<p><strong>Create NetworkPolicy</strong></p>
<p>We create the correct <em>NP</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 24_np.yaml create
</span></span></code></pre></div><p>And test again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.25:1111
</span></span><span style="display:flex;"><span>database one
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.23:2222
</span></span><span style="display:flex;"><span>database two
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ k -n project-snake exec backend-0 -- curl -s 10.44.0.22:3333
</span></span><span style="display:flex;"><span>^C
</span></span></code></pre></div><p>Also helpful to use <code>kubectl describe</code> on the <em>NP</em> to see how k8s has interpreted the policy.</p>
<p>Great, looking more secure. Task done.</p>
<h2 id="question-25--etcd-snapshot-save-and-restore">Question 25 | Etcd Snapshot Save and Restore</h2>
<h3 id="question-24">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c3-CCC</code></p>
<p>Make a backup of etcd running on cluster3-controlplane1 and save it on the controlplane node at <code>/tmp/etcd-backup.db</code>.</p>
<p>Then create any kind of <em>Pod</em> in the cluster.</p>
<p>Finally restore the backup, confirm the cluster is still working and that the created <em>Pod</em> is no longer with us.</p>
<h3 id="ref-7">Ref</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/configure-upgrade-etcd/">https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/configure-upgrade-etcd/</a></p>
<h3 id="answer-24">Answer</h3>
<h4 id="etcd-backup">Etcd Backup</h4>
<p>First we log into the controlplane and try to create a snapshop of etcd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster3-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot save /tmp/etcd-backup.db
</span></span><span style="display:flex;"><span>Error:  rpc error: code <span style="color:#f92672">=</span> Unavailable desc <span style="color:#f92672">=</span> transport is closing
</span></span></code></pre></div><p>But it fails because we need to authenticate ourselves. For the necessary information we can check the etc manifest:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# vim /etc/kubernetes/manifests/etcd.yaml
</span></span></code></pre></div><p>We only check the <code>etcd.yaml</code> for necessary information we don&rsquo;t change it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/manifests/etcd.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">component</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">advertise-client-urls=https://192.168.100.31:2379</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cert-file=/etc/kubernetes/pki/etcd/server.crt                          </span> <span style="color:#75715e"># use</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">client-cert-auth=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">data-dir=/var/lib/etcd</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">initial-advertise-peer-urls=https://192.168.100.31:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">initial-cluster=cluster3-controlplane1=https://192.168.100.31:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">key-file=/etc/kubernetes/pki/etcd/server.key                           </span> <span style="color:#75715e"># use</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-client-urls=https://127.0.0.1:2379,https://192.168.100.31:2379  </span> <span style="color:#75715e"># use</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-metrics-urls=http://127.0.0.1:2381</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-peer-urls=https://192.168.100.31:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">name=cluster3-controlplane1</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-client-cert-auth=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-key-file=/etc/kubernetes/pki/etcd/peer.key</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt                   </span> <span style="color:#75715e"># use</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">snapshot-count=10000</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">k8s.gcr.io/etcd:3.3.15-0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureThreshold</span>: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">host</span>: <span style="color:#ae81ff">127.0.0.1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/health</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">2381</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTP</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">initialDelaySeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">timeoutSeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/lib/etcd</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd-data</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/kubernetes/pki/etcd</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd-certs</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostNetwork</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">priorityClassName</span>: <span style="color:#ae81ff">system-cluster-critical</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/etc/kubernetes/pki/etcd</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">DirectoryOrCreate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd-certs</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/var/lib/etcd                                                    </span> <span style="color:#75715e"># important</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">DirectoryOrCreate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd-data</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>But we also know that the api-server is connecting to etcd, so we can check how its manifest is configured:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep etcd
</span></span><span style="display:flex;"><span>    - --etcd-cafile<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/ca.crt
</span></span><span style="display:flex;"><span>    - --etcd-certfile<span style="color:#f92672">=</span>/etc/kubernetes/pki/apiserver-etcd-client.crt
</span></span><span style="display:flex;"><span>    - --etcd-keyfile<span style="color:#f92672">=</span>/etc/kubernetes/pki/apiserver-etcd-client.key
</span></span><span style="display:flex;"><span>    - --etcd-servers<span style="color:#f92672">=</span>https://127.0.0.1:2379
</span></span></code></pre></div><p>We use the authentication information and pass it to etcdctl:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot save /tmp/etcd-backup.db <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cacert /etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cert /etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--key /etc/kubernetes/pki/etcd/server.key
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Snapshot saved at /tmp/etcd-backup.db
</span></span></code></pre></div><blockquote>
<p><strong>NOTE:</strong> Dont use <code>snapshot status</code> because it can alter the snapshot file and render it invalid</p>
</blockquote>
<h4 id="etcd-restore">Etcd restore</h4>
<p>Now create a <em>Pod</em> in the cluster and wait for it to be running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# kubectl run test --image<span style="color:#f92672">=</span>nginx
</span></span><span style="display:flex;"><span>pod/test created
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# kubectl get pod -l run<span style="color:#f92672">=</span>test -w
</span></span><span style="display:flex;"><span>NAME   READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>test   1/1     Running   <span style="color:#ae81ff">0</span>          60s
</span></span></code></pre></div><blockquote>
<p><strong>NOTE:</strong> If you didn&rsquo;t solve questions 18 or 20 and cluster3 doesn&rsquo;t have a ready worker node then the created pod might stay in a Pending state. This is still ok for this task.</p>
</blockquote>
<p>Next we stop all controlplane components:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@cluster3-controlplane1:~# cd /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>root@cluster3-controlplane1:/etc/kubernetes/manifests# mv * ..
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>root@cluster3-controlplane1:/etc/kubernetes/manifests# watch crictl ps
</span></span></code></pre></div><p>Now we restore the snapshot into a specific directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot restore /tmp/etcd-backup.db <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--data-dir /var/lib/etcd-backup <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cacert /etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cert /etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--key /etc/kubernetes/pki/etcd/server.key
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2020-09-04 16:50:19.650804 I | mvcc: restore compact to <span style="color:#ae81ff">9935</span>
</span></span><span style="display:flex;"><span>2020-09-04 16:50:19.659095 I | etcdserver/membership: added member 8e9e05c52164694d <span style="color:#f92672">[</span>http://localhost:2380<span style="color:#f92672">]</span> to cluster cdf818194e3a8c32
</span></span></code></pre></div><p>We could specify another host to make the backup from by using <code>etcdctl --endpoints http://IP</code>, but here we just use the default value which is: <code>http://127.0.0.1:2379,http://127.0.0.1:4001</code>.</p>
<p>The restored files are located at the new folder <code>/var/lib/etcd-backup</code>, now we have to tell etcd to use that directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# vim /etc/kubernetes/etcd.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/etcd.yaml</span>
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  creationTimestamp: null
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    component: etcd
</span></span><span style="display:flex;"><span>    tier: control-plane
</span></span><span style="display:flex;"><span>  name: etcd
</span></span><span style="display:flex;"><span>  namespace: kube-system
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - mountPath: /etc/kubernetes/pki/etcd
</span></span><span style="display:flex;"><span>      name: etcd-certs
</span></span><span style="display:flex;"><span>  hostNetwork: true
</span></span><span style="display:flex;"><span>  priorityClassName: system-cluster-critical
</span></span><span style="display:flex;"><span>  volumes:
</span></span><span style="display:flex;"><span>  - hostPath:
</span></span><span style="display:flex;"><span>      path: /etc/kubernetes/pki/etcd
</span></span><span style="display:flex;"><span>      type: DirectoryOrCreate
</span></span><span style="display:flex;"><span>    name: etcd-certs
</span></span><span style="display:flex;"><span>  - hostPath:
</span></span><span style="display:flex;"><span>      path: /var/lib/etcd-backup                <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>      type: DirectoryOrCreate
</span></span><span style="display:flex;"><span>    name: etcd-data
</span></span><span style="display:flex;"><span>status: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><p>Now we move all controlplane yaml again into the manifest directory. Give it some time (up to several minutes) for etcd to restart and for the api-server to be reachable again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@cluster3-controlplane1:/etc/kubernetes/manifests# mv ../*.yaml .
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>root@cluster3-controlplane1:/etc/kubernetes/manifests# watch crictl ps
</span></span></code></pre></div><p>Then we check again for the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster3-controlplane1:~# kubectl get pod -l run<span style="color:#f92672">=</span>test
</span></span><span style="display:flex;"><span>No resources found in default namespace.
</span></span></code></pre></div><p>Awesome, backup and restore worked as our pod is gone.</p>
<h2 id="extra-question-1--find-pods-first-to-be-terminated">Extra Question 1 | Find Pods first to be terminated</h2>
<h3 id="question-25">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>Check all available <em>Pods</em> in the <em>Namespace</em> <code>project-c13</code> and find the names of those that would probably be terminated first if the <em>nodes</em> run out of resources (cpu or memory) to schedule all <em>Pods</em>. Write the <em>Pod</em> names into <code>/opt/course/e1/pods-not-stable.txt</code>.</p>
<h3 id="answer-25">Answer</h3>
<p>When available cpu or memory resources on the nodes reach their limit, Kubernetes will look for <em>Pods</em> that are using more resources than they requested. These will be the first candidates for termination. If some <em>Pods</em> containers have no resource requests/limits set, then by default those are considered to use more than requested.</p>
<p>Kubernetes assigns Quality of Service classes to <em>Pods</em> based on the defined resources and limits, read more here: <a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod">https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod</a></p>
<p>Hence we should look for <em>Pods</em> without resource requests defined, we can do this with a manual approach:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-c13 describe pod | less -p Requests <span style="color:#75715e"># describe all pods and highlight Requests</span>
</span></span></code></pre></div><p>Or we do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-c13 describe pod | egrep <span style="color:#e6db74">&#34;^(Name:|    Requests:)&#34;</span> -A1
</span></span></code></pre></div><p>We see that the <em>Pods</em> of <em>Deployment</em> <code>c13-3cc-runner-heavy</code> don&rsquo;t have any resources requests specified. Hence our answer would be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/e1/pods-not-stable.txt</span>
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-djtv9map
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-v8kf5map
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-wwpb4map
</span></span><span style="display:flex;"><span>o3db-0
</span></span><span style="display:flex;"><span>o3db-1 <span style="color:#75715e"># maybe not existing if already removed via previous scenario </span>
</span></span></code></pre></div><p>To automate this process you could use jsonpath like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k -n project-c13 get pod <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{range .items[*]} {.metadata.name}{.spec.containers[*].resources}{&#39;\n&#39;}&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> c13-2x3-api-86784557bd-cgs8gmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:20Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-api-86784557bd-lnxvjmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:20Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-api-86784557bd-mnp77map<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:20Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-6hbgtmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-g57nqmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-hfd5vmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-jfx64map<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-r89mgmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-2x3-web-769c989898-wtgxlmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-98c8b5469-dzqhrmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:30m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-98c8b5469-hbtdvmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:30m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-98c8b5469-n9lswmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:30m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-heavy-65588d7d6-djtv9map<span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-heavy-65588d7d6-v8kf5map<span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span> c13-3cc-runner-heavy-65588d7d6-wwpb4map<span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span> c13-3cc-web-675456bcd-glpq6map<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-web-675456bcd-knlpxmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-web-675456bcd-nfhp9map<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> c13-3cc-web-675456bcd-twn7mmap<span style="color:#f92672">[</span>requests:map<span style="color:#f92672">[</span>cpu:50m memory:10Mi<span style="color:#f92672">]]</span>
</span></span><span style="display:flex;"><span> o3db-0<span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span> o3db-1<span style="color:#f92672">{}</span>
</span></span></code></pre></div><p>This lists all <em>Pod</em> names and their requests/limits, hence we see the three <em>Pods</em> without those defined.</p>
<p>Or we look for the Quality of Service classes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pods -n project-c13 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{range .items[*]}{.metadata.name} {.status.qosClass}{&#39;\n&#39;}&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>c13-2x3-api-86784557bd-cgs8g Burstable
</span></span><span style="display:flex;"><span>c13-2x3-api-86784557bd-lnxvj Burstable
</span></span><span style="display:flex;"><span>c13-2x3-api-86784557bd-mnp77 Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-6hbgt Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-g57nq Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-hfd5v Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-jfx64 Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-r89mg Burstable
</span></span><span style="display:flex;"><span>c13-2x3-web-769c989898-wtgxl Burstable
</span></span><span style="display:flex;"><span>c13-3cc-runner-98c8b5469-dzqhr Burstable
</span></span><span style="display:flex;"><span>c13-3cc-runner-98c8b5469-hbtdv Burstable
</span></span><span style="display:flex;"><span>c13-3cc-runner-98c8b5469-n9lsw Burstable
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-djtv9 BestEffort
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-v8kf5 BestEffort
</span></span><span style="display:flex;"><span>c13-3cc-runner-heavy-65588d7d6-wwpb4 BestEffort
</span></span><span style="display:flex;"><span>c13-3cc-web-675456bcd-glpq6 Burstable
</span></span><span style="display:flex;"><span>c13-3cc-web-675456bcd-knlpx Burstable
</span></span><span style="display:flex;"><span>c13-3cc-web-675456bcd-nfhp9 Burstable
</span></span><span style="display:flex;"><span>c13-3cc-web-675456bcd-twn7m Burstable
</span></span><span style="display:flex;"><span>o3db-0 BestEffort
</span></span><span style="display:flex;"><span>o3db-1 BestEffort
</span></span></code></pre></div><p>Here we see three with BestEffort, which <em>Pods</em> get that don&rsquo;t have any memory or cpu limits or requests defined.</p>
<p>A good practice is to always set resource requests and limits. If you don&rsquo;t know the values your containers should have you can find this out using metric tools like Prometheus. You can also use <code>kubectl top pod</code> or even <code>kubectl exec</code> into the container and use <code>top</code> and similar tools.</p>
<h2 id="extra-question-2--curl-manually-contact-api">Extra Question 2 | Curl Manually Contact API</h2>
<h3 id="question-26">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>There is an existing <em>ServiceAccount</em> <code>secret-reader</code> in <em>Namespace</em> <code>project-hamster</code>. Create a <em>Pod</em> of image <code>curlimages/curl:7.65.3</code> named <code>tmp-api-contact</code> which uses this <em>ServiceAccount</em>. Make sure the container keeps running.</p>
<p>Exec into the <em>Pod</em> and use <code>curl</code> to access the Kubernetes Api of that cluster manually, listing all available secrets. You can ignore insecure https connection. Write the command(s) for this into file <code>/opt/course/e4/list-secrets.sh</code>.</p>
<h3 id="answer-26">Answer</h3>
<p><a href="https://kubernetes.io/docs/tasks/run-application/access-api-from-pod">https://kubernetes.io/docs/tasks/run-application/access-api-from-pod</a></p>
<p>It&rsquo;s important to understand how the Kubernetes API works. For this it helps connecting to the api manually, for example using curl. You can find information fast by search in the Kubernetes docs for &ldquo;curl api&rdquo; for example.</p>
<p>First we create our <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run tmp-api-contact <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --image<span style="color:#f92672">=</span>curlimages/curl:7.65.3 $do <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --command &gt; e2.yaml -- sh -c <span style="color:#e6db74">&#39;sleep 1d&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim e2.yaml
</span></span></code></pre></div><p>Add the service account name and <em>Namespace</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># e2.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">tmp-api-contact</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tmp-api-contact</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-hamster         </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">secret-reader  </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sh</span>
</span></span><span style="display:flex;"><span>    - -<span style="color:#ae81ff">c</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sleep 1d</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">curlimages/curl:7.65.3</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tmp-api-contact</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>Then run and exec into:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f 6.yaml create
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k -n project-hamster exec tmp-api-contact -it -- sh
</span></span></code></pre></div><p>Once on the container we can try to connect to the api using <code>curl</code>, the api is usually available via the <em>Service</em> named <code>kubernetes</code> in <em>Namespace</em> <code>default</code> (You should know how dns resolution works across <em>Namespaces</em>.). Else we can find the endpoint IP via environment variables running <code>env</code>.</p>
<p>So now we can do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>curl https://kubernetes.default
</span></span><span style="display:flex;"><span>curl -k https://kubernetes.default <span style="color:#75715e"># ignore insecure as allowed in ticket description</span>
</span></span><span style="display:flex;"><span>curl -k https://kubernetes.default/api/v1/secrets <span style="color:#75715e"># should show Forbidden 403</span>
</span></span></code></pre></div><p>The last command shows 403 forbidden, this is because we are not passing any authorisation information with us. The Kubernetes Api Server thinks we are connecting as <code>system:anonymous</code>. We want to change this and connect using the <em>Pods</em> <em>ServiceAccount</em> named <code>secret-reader</code>.</p>
<p>We find the the token in the mounted folder at <code>/var/run/secrets/kubernetes.io/serviceaccount</code>, so we do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ TOKEN<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>cat /var/run/secrets/kubernetes.io/serviceaccount/token<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>➜ curl -k https://kubernetes.default/api/v1/secrets -H <span style="color:#e6db74">&#34;Authorization: Bearer </span><span style="color:#e6db74">${</span>TOKEN<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span></span><span style="display:flex;"><span>                                 Dload  Upload   Total   Spent    Left  Speed
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">0</span>     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">0</span>     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">0</span>     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span> --:--:-- --:--:-- --:--:--     0<span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;kind&#34;</span>: <span style="color:#e6db74">&#34;SecretList&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;apiVersion&#34;</span>: <span style="color:#e6db74">&#34;v1&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;metadata&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;selfLink&#34;</span>: <span style="color:#e6db74">&#34;/api/v1/secrets&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;resourceVersion&#34;</span>: <span style="color:#e6db74">&#34;10697&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;items&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;metadata&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;default-token-5zjbd&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;namespace&#34;</span>: <span style="color:#e6db74">&#34;default&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;selfLink&#34;</span>: <span style="color:#e6db74">&#34;/api/v1/namespaces/default/secrets/default-token-5zjbd&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;uid&#34;</span>: <span style="color:#e6db74">&#34;315dbfd9-d235-482b-8bfc-c6167e7c1461&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;resourceVersion&#34;</span>: <span style="color:#e6db74">&#34;342&#34;</span>,
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>Now we&rsquo;re able to list all <em>Secrets</em>, registering as the <em>ServiceAccount</em> <code>secret-reader</code> under which our <em>Pod</em> is running.</p>
<p>To use encrypted https connection we can run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>CACERT<span style="color:#f92672">=</span>/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
</span></span><span style="display:flex;"><span>curl --cacert <span style="color:#e6db74">${</span>CACERT<span style="color:#e6db74">}</span> https://kubernetes.default/api/v1/secrets -H <span style="color:#e6db74">&#34;Authorization: Bearer </span><span style="color:#e6db74">${</span>TOKEN<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><p>For troubleshooting we could also check if the <em>ServiceAccount</em> is actually able to list <em>Secrets</em> using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k auth can-i get secret --as system:serviceaccount:project-hamster:secret-reader
</span></span><span style="display:flex;"><span>yes
</span></span></code></pre></div><p>Finally write the commands into the requested location:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># /opt/course/e4/list-secrets.sh</span>
</span></span><span style="display:flex;"><span>TOKEN<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>cat /var/run/secrets/kubernetes.io/serviceaccount/token<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>curl -k https://kubernetes.default/api/v1/secrets -H <span style="color:#e6db74">&#34;Authorization: Bearer </span><span style="color:#e6db74">${</span>TOKEN<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><h1 id="cka-simulator-preview-kubernetes-129">CKA Simulator Preview Kubernetes 1.29</h1>
<p><a href="https://killer.sh/">https://killer.sh</a></p>
<p>This is a preview of the full CKA Simulator course content.</p>
<p>The full course contains 25 scenarios from all the CKA areas. The course also provides a browser terminal which is a very close replica of the original one. This is great to get used and comfortable before the real exam. After the test session (120 minutes), or if you stop it early, you&rsquo;ll get access to all questions and their detailed solutions. You&rsquo;ll have 36 hours cluster access in total which means even after the session, once you have the solutions, you can still play around.</p>
<p>The following preview will give you an idea of what the full course will provide. These preview questions are in addition to the 25 of the full course. But the preview questions are part of the same CKA simulation environment which we setup for you, so with access to the full course you can solve these too.</p>
<p>The answers provided here assume that you did run the initial terminal setup suggestions as provided in the tips section, but especially:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>alias k<span style="color:#f92672">=</span>kubectl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export <span style="color:#66d9ef">do</span><span style="color:#f92672">=</span><span style="color:#e6db74">&#34;-o yaml --dry-run=client&#34;</span> 
</span></span></code></pre></div><p><strong>These questions can be solved in the test environment provided through the CKA Simulator</strong></p>
<h2 id="preview-question-1">Preview Question 1</h2>
<h3 id="question-27">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>The cluster admin asked you to find out the following information about etcd running on cluster2-controlplane1:</p>
<ul>
<li>Server private key location</li>
<li>Server certificate expiration date</li>
<li>Is client certificate authentication enabled</li>
</ul>
<p>Write these information into <code>/opt/course/p1/etcd-info.txt</code></p>
<p>Finally you&rsquo;re asked to save an etcd snapshot at <code>/etc/etcd-snapshot.db</code> on cluster2-controlplane1 and display its status.</p>
<h3 id="answer-27">Answer</h3>
<p><strong>Find out etcd information</strong></p>
<p>Let&rsquo;s check the nodes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE    VERSION
</span></span><span style="display:flex;"><span>cluster2-controlplane1   Ready    control-plane   89m   v1.29.0
</span></span><span style="display:flex;"><span>cluster2-node1           Ready    &lt;none&gt;          87m   v1.29.0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ ssh cluster2-controlplane1
</span></span></code></pre></div><p>First we check how etcd is setup in this cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubectl -n kube-system get pod
</span></span><span style="display:flex;"><span>NAME                                                READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>coredns-66bff467f8-k8f48                            1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>coredns-66bff467f8-rn8tr                            1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>etcd-cluster2-controlplane1                         1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>kube-apiserver-cluster2-controlplane1               1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>kube-controller-manager-cluster2-controlplane1      1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>kube-proxy-qthfg                                    1/1     Running   <span style="color:#ae81ff">0</span>          25h
</span></span><span style="display:flex;"><span>kube-proxy-z55lp                                    1/1     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>kube-scheduler-cluster2-controlplane1               1/1     Running   <span style="color:#ae81ff">1</span>          26h
</span></span><span style="display:flex;"><span>weave-net-cqdvt                                     2/2     Running   <span style="color:#ae81ff">0</span>          26h
</span></span><span style="display:flex;"><span>weave-net-dxzgh                                     2/2     Running   <span style="color:#ae81ff">1</span>          25h
</span></span></code></pre></div><p>We see it&rsquo;s running as a <em>Pod</em>, more specific a static <em>Pod</em>. So we check for the default kubelet directory for static manifests:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# find /etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-controller-manager.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/etcd.yaml
</span></span><span style="display:flex;"><span>/etc/kubernetes/manifests/kube-scheduler.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# vim /etc/kubernetes/manifests/etcd.yaml
</span></span></code></pre></div><p>So we look at the yaml and the parameters with which etcd is started:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/manifests/etcd.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">component</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">advertise-client-urls=https://192.168.102.11:2379</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cert-file=/etc/kubernetes/pki/etcd/server.crt             </span> <span style="color:#75715e"># server certificate</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">client-cert-auth=true                                     </span> <span style="color:#75715e"># enabled</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">data-dir=/var/lib/etcd</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">initial-advertise-peer-urls=https://192.168.102.11:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">initial-cluster=cluster2-controlplane1=https://192.168.102.11:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">key-file=/etc/kubernetes/pki/etcd/server.key              </span> <span style="color:#75715e"># server private key</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-client-urls=https://127.0.0.1:2379,https://192.168.102.11:2379</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-metrics-urls=http://127.0.0.1:2381</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">listen-peer-urls=https://192.168.102.11:2380</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">name=cluster2-controlplane1</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-client-cert-auth=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-key-file=/etc/kubernetes/pki/etcd/peer.key</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">snapshot-count=10000</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>We see that client authentication is enabled and also the requested path to the server private key, now let&rsquo;s find out the expiration of the server certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# openssl x509  -noout -text -in /etc/kubernetes/pki/etcd/server.crt | grep Validity -A2
</span></span><span style="display:flex;"><span>        Validity
</span></span><span style="display:flex;"><span>            Not Before: Sep <span style="color:#ae81ff">13</span> 13:01:31 <span style="color:#ae81ff">2021</span> GMT
</span></span><span style="display:flex;"><span>            Not After : Sep <span style="color:#ae81ff">13</span> 13:01:31 <span style="color:#ae81ff">2022</span> GMT
</span></span></code></pre></div><p>There we have it. Let&rsquo;s write the information into the requested file:</p>
<pre tabindex="0"><code># /opt/course/p1/etcd-info.txt
Server private key location: /etc/kubernetes/pki/etcd/server.key
Server certificate expiration date: Sep 13 13:01:31 2022 GMT
Is client certificate authentication enabled: yes
</code></pre><p><strong>Create etcd snapshot</strong></p>
<p>First we try:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot save /etc/etcd-snapshot.db
</span></span></code></pre></div><p>We get the endpoint also from the yaml. But we need to specify more parameters, all of which we can find the yaml declaration above:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot save /etc/etcd-snapshot.db <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cacert /etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cert /etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--key /etc/kubernetes/pki/etcd/server.key
</span></span></code></pre></div><p>This worked. Now we can output the status of the backup file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl snapshot status /etc/etcd-snapshot.db
</span></span><span style="display:flex;"><span>4d4e953, 7213, 1291, 2.7 MB
</span></span></code></pre></div><p>The status shows:</p>
<ul>
<li>Hash: 4d4e953</li>
<li>Revision: 7213</li>
<li>Total Keys: 1291</li>
<li>Total Size: 2.7 MB</li>
</ul>
<h2 id="preview-question-2">Preview Question 2</h2>
<h3 id="question-28">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c1-H</code></p>
<p>You&rsquo;re asked to confirm that kube-proxy is running correctly on all nodes. For this perform the following in <em>Namespace</em> <code>project-hamster</code>:</p>
<p>Create a new <em>Pod</em> named <code>p2-pod</code> with two containers, one of image <code>nginx:1.21.3-alpine</code> and one of image <code>busybox:1.31</code>. Make sure the busybox container keeps running for some time.</p>
<p>Create a new <em>Service</em> named <code>p2-service</code> which exposes that <em>Pod</em> internally in the cluster on port 3000-&gt;80.</p>
<p>Find the kube-proxy container on all nodes <code>cluster1-controlplane1</code>, <code>cluster1-node1</code> and <code>cluster1-node2</code> and make sure that it&rsquo;s using iptables. Use command <code>crictl</code> for this.</p>
<p>Write the iptables rules of all nodes belonging the created <em>Service</em> <code>p2-service</code> into file <code>/opt/course/p2/iptables.txt</code>.</p>
<p>Finally delete the <em>Service</em> and confirm that the iptables rules are gone from all nodes.</p>
<h3 id="answer-28">Answer</h3>
<h4 id="create-the-pod">Create the <em>Pod</em></h4>
<p>First we create the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># check out export statement on top which allows us to use $do</span>
</span></span><span style="display:flex;"><span>k run p2-pod --image<span style="color:#f92672">=</span>nginx:1.21.3-alpine $do &gt; p2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vim p2.yaml
</span></span></code></pre></div><p>Next we add the requested second container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># p2.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">p2-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">p2-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-hamster            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1.21.3-alpine</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">p2-pod</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:1.31                 </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">c2                            </span> <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;sleep 1d&#34;</span>]    <span style="color:#75715e"># add</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsPolicy</span>: <span style="color:#ae81ff">ClusterFirst</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><p>And we create the <em>Pod</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -f p2.yaml create
</span></span></code></pre></div><h4 id="create-the-service">Create the <em>Service</em></h4>
<p>Next we create the <em>Service</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster expose pod p2-pod --name p2-service --port <span style="color:#ae81ff">3000</span> --target-port <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>This will create a yaml like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#e6db74">&#34;2020-04-30T20:58:14Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">p2-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">managedFields</span>:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">operation</span>: <span style="color:#ae81ff">Update</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">time</span>: <span style="color:#e6db74">&#34;2020-04-30T20:58:14Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">p2-service</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">project-hamster</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resourceVersion</span>: <span style="color:#e6db74">&#34;11071&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selfLink</span>: <span style="color:#ae81ff">/api/v1/namespaces/project-hamster/services/p2-service</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">uid</span>: <span style="color:#ae81ff">2a1c0842-7fb6-4e94-8cdb-1602a3b1e7d2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterIP</span>: <span style="color:#ae81ff">10.97.45.18</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">p2-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sessionAffinity</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">loadBalancer</span>: {}
</span></span></code></pre></div><p>We should confirm <em>Pods</em> and <em>Services</em> are connected, hence the <em>Service</em> should have <em>Endpoints</em>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster get pod,svc,ep
</span></span></code></pre></div><h4 id="confirm-kube-proxy-is-running-and-is-using-iptables">Confirm kube-proxy is running and is using iptables</h4>
<p>First we get nodes in the cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get node
</span></span><span style="display:flex;"><span>NAME                     STATUS   ROLES           AGE   VERSION
</span></span><span style="display:flex;"><span>cluster1-controlplane1   Ready    control-plane   98m   v1.29.0
</span></span><span style="display:flex;"><span>cluster1-node1           Ready    &lt;none&gt;          96m   v1.29.0
</span></span><span style="display:flex;"><span>cluster1-node2           Ready    &lt;none&gt;          95m   v1.29.0
</span></span></code></pre></div><p>The idea here is to log into every node, find the kube-proxy container and check its logs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1$ crictl ps | grep kube-proxy
</span></span><span style="display:flex;"><span>27b6a18c0f89c       36c4ebbc9d979       <span style="color:#ae81ff">3</span> hours ago         Running             kube-proxy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster1-controlplane1~# crictl logs 27b6a18c0f89c
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>I0913 12:53:03.096620       <span style="color:#ae81ff">1</span> server_others.go:212<span style="color:#f92672">]</span> Using iptables Proxier.
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>This should be repeated on every node and result in the same output <code>Using iptables Proxier</code>.</p>
<h4 id="check-kube-proxy-is-creating-iptables-rules">Check kube-proxy is creating iptables rules</h4>
<p>Now we check the iptables rules on every node first manually:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1 iptables-save | grep p2-service
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -s 10.44.0.20/32 -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -m tcp -j DNAT --to-destination 10.44.0.20:80
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-SVC-2A6FNMCK6FDH7PJH
</span></span><span style="display:flex;"><span>-A KUBE-SVC-2A6FNMCK6FDH7PJH -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-SEP-6U447UXLLQIKP7BB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node1 iptables-save | grep p2-service
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -s 10.44.0.20/32 -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -m tcp -j DNAT --to-destination 10.44.0.20:80
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-SVC-2A6FNMCK6FDH7PJH
</span></span><span style="display:flex;"><span>-A KUBE-SVC-2A6FNMCK6FDH7PJH -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-SEP-6U447UXLLQIKP7BB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node2 iptables-save | grep p2-service
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -s 10.44.0.20/32 -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SEP-6U447UXLLQIKP7BB -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -m tcp -j DNAT --to-destination 10.44.0.20:80
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-MARK-MASQ
</span></span><span style="display:flex;"><span>-A KUBE-SERVICES -d 10.97.45.18/32 -p tcp -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service: cluster IP&#34;</span> -m tcp --dport <span style="color:#ae81ff">3000</span> -j KUBE-SVC-2A6FNMCK6FDH7PJH
</span></span><span style="display:flex;"><span>-A KUBE-SVC-2A6FNMCK6FDH7PJH -m comment --comment <span style="color:#e6db74">&#34;project-hamster/p2-service:&#34;</span> -j KUBE-SEP-6U447UXLLQIKP7BB
</span></span></code></pre></div><p>Great. Now let&rsquo;s write these logs into the requested file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1 iptables-save | grep p2-service &gt;&gt; /opt/course/p2/iptables.txt
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node1 iptables-save | grep p2-service &gt;&gt; /opt/course/p2/iptables.txt
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node2 iptables-save | grep p2-service &gt;&gt; /opt/course/p2/iptables.txt
</span></span></code></pre></div><h4 id="delete-the-service-and-confirm-iptables-rules-are-gone">Delete the <em>Service</em> and confirm iptables rules are gone</h4>
<p>Delete the <em>Service</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k -n project-hamster delete svc p2-service
</span></span></code></pre></div><p>And confirm the iptables rules are gone:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster1-controlplane1 iptables-save | grep p2-service
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node1 iptables-save | grep p2-service
</span></span><span style="display:flex;"><span>➜ ssh cluster1-node2 iptables-save | grep p2-service
</span></span></code></pre></div><p>Done.</p>
<p>Kubernetes <em>Services</em> are implemented using iptables rules (with default config) on all nodes. Every time a <em>Service</em> has been altered, created, deleted or <em>Endpoints</em> of a <em>Service</em> have changed, the kube-apiserver contacts every node&rsquo;s kube-proxy to update the iptables rules according to the current state.</p>
<h2 id="preview-question-3">Preview Question 3</h2>
<h3 id="question-29">Question</h3>
<p>Use context: <code>kubectl config use-context k8s-c2-AC</code></p>
<p>Create a <em>Pod</em> named <code>check-ip</code> in <em>Namespace</em> <code>default</code> using image <code>httpd:2.4.41-alpine</code>. Expose it on port 80 as a ClusterIP <em>Service</em> named <code>check-ip-service</code>. Remember/output the IP of that <em>Service</em>.</p>
<p>Change the Service CIDR to <code>11.96.0.0/12</code> for the cluster.</p>
<p>Then create a second <em>Service</em> named <code>check-ip-service2</code> pointing to the same <em>Pod</em> to check if your settings did take effect. Finally check if the IP of the first <em>Service</em> has changed.</p>
<h3 id="answer-29">Answer</h3>
<p>Let&rsquo;s create the <em>Pod</em> and expose it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k run check-ip --image<span style="color:#f92672">=</span>httpd:2.4.41-alpine
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k expose pod check-ip --name check-ip-service --port <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>And check the <em>Pod</em> and <em>Service</em> ips:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get svc,ep -l run<span style="color:#f92672">=</span>check-ip
</span></span><span style="display:flex;"><span>NAME                       TYPE        CLUSTER-IP    EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>service/check-ip-service   ClusterIP   10.104.3.45   &lt;none&gt;        80/TCP    8s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                         ENDPOINTS      AGE
</span></span><span style="display:flex;"><span>endpoints/check-ip-service   10.44.0.3:80   7s
</span></span></code></pre></div><p>Now we change the <em>Service</em> CIDR on the kube-apiserver:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ ssh cluster2-controlplane1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# vim /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/manifests/kube-apiserver.yaml</span>
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  creationTimestamp: null
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    component: kube-apiserver
</span></span><span style="display:flex;"><span>    tier: control-plane
</span></span><span style="display:flex;"><span>  name: kube-apiserver
</span></span><span style="display:flex;"><span>  namespace: kube-system
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-apiserver
</span></span><span style="display:flex;"><span>    - --advertise-address<span style="color:#f92672">=</span>192.168.100.21
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - --service-account-key-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/sa.pub
</span></span><span style="display:flex;"><span>    - --service-cluster-ip-range<span style="color:#f92672">=</span>11.96.0.0/12             <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    - --tls-cert-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/apiserver.crt
</span></span><span style="display:flex;"><span>    - --tls-private-key-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/apiserver.key
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p><strong>Give it a bit for the kube-apiserver and controller-manager to restart</strong></p>
<p>Wait for the api to be up again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# kubectl -n kube-system get pod | grep api
</span></span><span style="display:flex;"><span>kube-apiserver-cluster2-controlplane1            1/1     Running   <span style="color:#ae81ff">0</span>              49s
</span></span></code></pre></div><p>Now we do the same for the controller manager:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">➜ root@cluster2-controlplane1:~# vim /etc/kubernetes/manifests/kube-controller-manager.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /etc/kubernetes/manifests/kube-controller-manager.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">component</span>: <span style="color:#ae81ff">kube-controller-manager</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kube-controller-manager</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">kube-controller-manager</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">allocate-node-cidrs=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authentication-kubeconfig=/etc/kubernetes/controller-manager.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authorization-kubeconfig=/etc/kubernetes/controller-manager.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">bind-address=127.0.0.1</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">client-ca-file=/etc/kubernetes/pki/ca.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cluster-cidr=10.244.0.0/16</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cluster-name=kubernetes</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">cluster-signing-key-file=/etc/kubernetes/pki/ca.key</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">controllers=*,bootstrapsigner,tokencleaner</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">kubeconfig=/etc/kubernetes/controller-manager.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">leader-elect=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">node-cidr-mask-size=24</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">root-ca-file=/etc/kubernetes/pki/ca.crt</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">service-account-private-key-file=/etc/kubernetes/pki/sa.key</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">service-cluster-ip-range=11.96.0.0/12        </span> <span style="color:#75715e"># change</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">use-service-account-credentials=true</span>
</span></span></code></pre></div><p><strong>Give it a bit for the scheduler to restart</strong>.</p>
<p>We can check if it was restarted using <code>crictl</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ root@cluster2-controlplane1:~# crictl ps | grep scheduler
</span></span><span style="display:flex;"><span>3d258934b9fd6    aca5ededae9c8    About a minute ago   Running    kube-scheduler ...
</span></span></code></pre></div><p>Checking our existing <em>Pod</em> and <em>Service</em> again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get pod,svc -l run<span style="color:#f92672">=</span>check-ip
</span></span><span style="display:flex;"><span>NAME           READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>pod/check-ip   1/1     Running   <span style="color:#ae81ff">0</span>          21m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>service/check-ip-service   ClusterIP   10.99.32.177   &lt;none&gt;        80/TCP    21m
</span></span></code></pre></div><p>Nothing changed so far. Now we create another <em>Service</em> like before:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>k expose pod check-ip --name check-ip-service2 --port <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>And check again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>➜ k get svc,ep -l run<span style="color:#f92672">=</span>check-ip
</span></span><span style="display:flex;"><span>NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>service/check-ip-service    ClusterIP   10.109.222.111   &lt;none&gt;        80/TCP    8m
</span></span><span style="display:flex;"><span>service/check-ip-service2   ClusterIP   11.111.108.194   &lt;none&gt;        80/TCP    6m32s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                          ENDPOINTS      AGE
</span></span><span style="display:flex;"><span>endpoints/check-ip-service    10.44.0.1:80   8m
</span></span><span style="display:flex;"><span>endpoints/check-ip-service2   10.44.0.1:80   6m13s
</span></span></code></pre></div><p>There we go, the new <em>Service</em> got an ip of the new specified range assigned. We also see that both <em>Services</em> have our <em>Pod</em> as endpoint.</p>
<h1 id="cka-tips-kubernetes-129">CKA Tips Kubernetes 1.29</h1>
<p>In this section we&rsquo;ll provide some tips on how to handle the CKA exam and browser terminal.</p>
<h2 id="knowledge">Knowledge</h2>
<p>Study all topics as proposed in the curriculum till you feel comfortable with all.</p>
<p><strong>General</strong></p>
<ul>
<li>Study all topics as proposed in the curriculum till you feel comfortable with all</li>
<li>Do 1 or 2 test session with this CKA Simulator. Understand the solutions and maybe try out other ways to achieve the same thing.</li>
<li>Setup your aliases, be fast and breath <code>kubectl</code></li>
<li>The majority of tasks in the CKA will also be around creating Kubernetes resources, like it&rsquo;s tested in the CKAD. So preparing a bit for the CKAD can&rsquo;t hurt.</li>
<li>Learn and Study the in-browser scenarios on <a href="https://killercoda.com/killer-shell-cka">https://killercoda.com/killer-shell-cka</a> (and maybe for CKAD <a href="https://killercoda.com/killer-shell-ckad">https://killercoda.com/killer-shell-ckad</a>)</li>
<li>Imagine and create your own scenarios to solve</li>
</ul>
<p><strong>Components</strong></p>
<ul>
<li>Understanding Kubernetes components and being able to fix and investigate clusters: <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster">https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster</a></li>
<li>Know advanced scheduling: <a href="https://kubernetes.io/docs/concepts/scheduling/kube-scheduler">https://kubernetes.io/docs/concepts/scheduling/kube-scheduler</a></li>
<li>When you have to fix a component (like kubelet) in one cluster, just check how it&rsquo;s setup on another node in the same or even another cluster. You can copy config files over etc</li>
<li>If you like you can look at <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes The Hard Way</a> once. But it&rsquo;s NOT necessary to do, the CKA is not that complex. But KTHW helps understanding the concepts</li>
<li>You should install your own cluster using kubeadm (one controlplane, one worker) in a VM or using a cloud provider and investigate the components</li>
<li>Know how to use Kubeadm to for example add nodes to a cluster</li>
<li>Know how to create an Ingress resources</li>
<li>Know how to snapshot/restore ETCD from another machine</li>
</ul>
<h2 id="cka-preparation">CKA Preparation</h2>
<p><strong>Read the Curriculum</strong></p>
<p><a href="https://github.com/cncf/curriculum">https://github.com/cncf/curriculum</a></p>
<p><strong>Read the Handbook</strong></p>
<p><a href="https://docs.linuxfoundation.org/tc-docs/certification/lf-handbook2">https://docs.linuxfoundation.org/tc-docs/certification/lf-handbook2</a></p>
<p><strong>Read the important tips</strong></p>
<p><a href="https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad">https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad</a></p>
<p><strong>Read the FAQ</strong></p>
<p><a href="https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad">https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad</a></p>
<h2 id="kubernetes-documentation">Kubernetes Documentation</h2>
<p>Get familiar with the Kubernetes documentation and be able to use the search. Allowed links are:</p>
<ul>
<li><a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
<li><a href="https://kubernetes.io/blog">https://kubernetes.io/blog</a></li>
<li><a href="https://helm.sh/docs">https://helm.sh/docs</a></li>
</ul>
<blockquote>
<p>*<strong>NOTE:*</strong> Verify the list <a href="https://docs.linuxfoundation.org/tc-docs/certification/certification-resources-allowed#certified-kubernetes-administrator-cka-and-certified-kubernetes-application-developer-ckad">here</a></p>
</blockquote>
<h2 id="the-test-environment--browser-terminal">The Test Environment / Browser Terminal</h2>
<p>You&rsquo;ll be provided with a browser terminal which uses Ubuntu 20. The standard shells included with a minimal install of Ubuntu 20 will be available, including bash.</p>
<p><strong>Laggin</strong></p>
<p>There could be some lagging, definitely make sure you are using a good internet connection because your webcam and screen are uploading all the time.</p>
<p><strong>Kubectl autocompletion and commands</strong></p>
<p>Autocompletion is configured by default, as well as the <code>k</code> alias <a href="https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad">source</a> and others:</p>
<p><code>kubectl</code> with <code>k</code> alias and Bash autocompletion</p>
<p><code>yq</code> and <code>jq</code>for YAML/JSON processing</p>
<p><code>tmux</code> for terminal multiplexing</p>
<p><code>curl</code> and <code>wget</code> for testing web services</p>
<p><code>man</code> and man pages for further documentation</p>
<p><strong>Copy &amp; Paste</strong></p>
<p>There could be issues copying text (like pod names) from the left task information into the terminal. Some suggested to &ldquo;hard&rdquo; hit or long hold <code>Cmd/Ctrl+C</code> a few times to take action. Apart from that copy and paste should just work like in normal terminals.</p>
<p><strong>Score</strong></p>
<p>There are 15-20 questions in the exam. Your results will be automatically checked according to the handbook. If you don&rsquo;t agree with the results you can request a review by contacting the Linux Foundation Support.</p>
<p><strong>Notepad &amp; Skipping Questions</strong></p>
<p>You have access to a simple notepad in the browser which can be used for storing any kind of plain text. It might makes sense to use this for saving skipped question numbers. This way it&rsquo;s possible to move some questions to the end.</p>
<p><strong>Contexts</strong></p>
<p>You&rsquo;ll receive access to various different clusters and resources in each. They provide you the exact command you need to run to connect to another cluster/context. But you should be comfortable working in different namespaces with <code>kubectl</code>.</p>
<h2 id="psi-bridge">PSI Bridge</h2>
<p>Starting with <a href="https://training.linuxfoundation.org/bridge-migration-2021">PSI Bridge</a>:</p>
<ul>
<li>The exam will now be taken using the PSI Secure Browser, which can be downloaded using the newest versions of Microsoft Edge, Safari, Chrome, or Firefox</li>
<li>Multiple monitors will no longer be permitted</li>
<li>Use of personal bookmarks will no longer be permitted</li>
</ul>
<p>The new ExamUI includes improved features such as:</p>
<ul>
<li>A remote desktop configured with the tools and software needed to complete the tasks</li>
<li>A timer that displays the actual time remaining (in minutes) and provides an alert with 30, 15, or 5 minute remaining</li>
<li>The content panel remains the same (presented on the Left Hand Side of the ExamUI)</li>
</ul>
<p>Read more <a href="https://training.linuxfoundation.org/bridge-migration-2021">here</a>.</p>
<h2 id="browser-terminal-setup">Browser Terminal Setup</h2>
<p>It should be considered to spend ~1 minute in the beginning to setup your terminal. In the real exam the vast majority of questions will be done from the main terminal. For few you might need to ssh into another machine. Just be aware that configurations to your shell will not be transferred in this case.</p>
<h4 id="minimal-setup">Minimal Setup</h4>
<p><strong>Alias</strong></p>
<p>The alias <code>k</code> for <code>kubectl</code> will already be configured together with autocompletion. In case not you can configure it using this <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet">link</a>.</p>
<p><strong>Vim</strong></p>
<p>The following settings will already be configured in your real exam environment in <code>~/.vimrc</code>. But it can never hurt to be able to type these down:</p>
<pre tabindex="0"><code>set tabstop=2
set expandtab
set shiftwidth=2
</code></pre><p>The <code>expandtab</code> make sure to use spaces for tabs. Memorize these and just type them down. You can&rsquo;t have any written notes with commands on your desktop etc.</p>
<h4 id="optional-setup">Optional Setup</h4>
<p><strong>Fast dry-run output</strong></p>
<pre tabindex="0"><code>export do=&#34;--dry-run=client -o yaml&#34;
</code></pre><p>This way you can just run <code>k run pod1 --image=nginx $do</code>. Short for &ldquo;dry output&rdquo;, but use whatever name you like.</p>
<p><strong>Fast pod delete</strong></p>
<pre tabindex="0"><code>export now=&#34;--force --grace-period 0&#34;
</code></pre><p>This way you can run <code>k delete pod1 $now</code> and don&rsquo;t have to wait for ~30 seconds termination time.</p>
<p><strong>Persist bash settings</strong></p>
<p>You can store aliases and other setup in <code>~/.bashrc</code> if you&rsquo;re planning on using different shells or <code>tmux</code>.</p>
<p><strong>Alias Namespace</strong></p>
<p>In addition you could define an alias like:</p>
<pre tabindex="0"><code>alias kn=&#39;kubectl config set-context --current --namespace &#39;
</code></pre><p>Which allows you to define the default namespace of the current context. Then once you switch a context or namespace you can just run:</p>
<pre tabindex="0"><code>kn default        # set default to default
kn my-namespace   # set default to my-namespace
</code></pre><p>But only do this if you used it before and are comfortable doing so. Else you need to specify the namespace for every call, which is also fine:</p>
<pre tabindex="0"><code>k -n my-namespace get all
k -n my-namespace get pod
... 
</code></pre><h3 id="be-fast">Be fast</h3>
<p>Use the <code>history</code> command to reuse already entered commands or use even faster history search through <strong>Ctrl r</strong> .</p>
<p>If a command takes some time to execute, like sometimes <code>kubectl delete pod x</code>. You can put a task in the background using <strong>Ctrl z</strong> and pull it back into foreground running command <code>fg</code>.</p>
<p>You can delete <em>pods</em> fast with:</p>
<pre tabindex="0"><code>k delete pod x --grace-period 0 --force


k delete pod x $now # if export from above is configured
</code></pre><h3 id="vim">Vim</h3>
<p>Be great with vim.</p>
<p><strong>toggle vim line numbers</strong></p>
<p>When in <code>vim</code> you can press <strong>Esc</strong> and type <code>:set number</code> or <code>:set nonumber</code> followed by <strong>Enter</strong> to toggle line numbers. This can be useful when finding syntax errors based on line - but can be bad when wanting to mark&amp;copy by mouse. You can also just jump to a line number with <strong>Esc</strong> <code>:22</code> + <strong>Enter</strong>.</p>
<p><strong>copy&amp;paste</strong></p>
<p>Get used to copy/paste/cut with vim:</p>
<pre tabindex="0"><code>Mark lines: Esc+V (then arrow keys)
Copy marked lines: y
Cut marked lines: d
Past lines: p or P
</code></pre><p><strong>Indent multiple lines</strong></p>
<p>To indent multiple lines press <strong>Esc</strong> and type <code>:set shiftwidth=2</code>. First mark multiple lines using <code>Shift v</code> and the up/down keys. Then to indent the marked lines press <code>&gt;</code> or <code>&lt;</code>. You can then press <code>.</code> to repeat the action.</p>
<h3 id="split-terminal-screen">Split terminal screen</h3>
<p>By default <code>tmux</code> is installed and can be used to split your one terminal into multiple. <strong>But</strong> just do this if you know your shit, because scrolling is different and copy&amp;pasting might be weird.</p>
<p><a href="https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux">https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux</a></p>

        </div>

        
        
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">大白猫</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
      2024-03-06
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>



        
        


        <footer class="post-footer">
          <div class="post-tags">
              <a href="https://zyt153.github.io/tags/k8s/">k8s</a>
                <a href="https://zyt153.github.io/tags/cka/">cka</a>
                
            </div>


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/cka-preparation/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">Preparation for CKA</span>
                <span class="prev-text nav-mobile">Prev</span>
              </a>
            
              <a class="next" href="/post/note_k8s_heima/">
                <span class="next-text nav-default">k8s学习笔记-黑马</span>
                <span class="prev-text nav-mobile">Next</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      


      
      

  

  
  
    <div class="post">
  <script
    src="https://giscus.app/client.js"
    data-repo="zyt153/zyt153.github.io"
    data-repo-id="R_kgDOKDTjhg"
    data-category="General"
    data-category-id="DIC_kwDOKDTjhs4CZI99"
    data-mapping="pathname"
    data-strict="0"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="top"
    data-theme="light"
    data-lang="en"
    
    crossorigin="anonymous"
    async
  ></script>
</div>

  

  
  

  

  

    

  

  


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">Table of Contents</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#pre-setup">Pre Setup</a></li>
    <li><a href="#question-1--contexts">Question 1 | Contexts</a>
      <ul>
        <li><a href="#question">Question</a></li>
        <li><a href="#my-answer">My Answer</a></li>
        <li><a href="#answer">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-2--schedule-pod-on-controlplane-nodes">Question 2 | Schedule Pod on Controlplane Nodes</a>
      <ul>
        <li><a href="#question-1">Question</a></li>
        <li><a href="#my-answer-1">My Answer</a></li>
        <li><a href="#answer-1">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-3--scale-down-statefulset">Question 3 | Scale down StatefulSet</a>
      <ul>
        <li><a href="#question-2">Question</a></li>
        <li><a href="#my-answer-2">My Answer</a></li>
        <li><a href="#answer-2">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-4--pod-ready-if-service-is-reachable">Question 4 | Pod Ready if Service is reachable</a>
      <ul>
        <li><a href="#question-3">Question</a></li>
        <li><a href="#my-answer-3">My Answer</a></li>
        <li><a href="#answer-3">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-5--kubectl-sorting">Question 5 | Kubectl sorting</a>
      <ul>
        <li><a href="#question-4">Question</a></li>
        <li><a href="#my-answer-4">My Answer</a></li>
        <li><a href="#answer-4">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-6--storage-pv-pvc-pod-volume">Question 6 | Storage, PV, PVC, Pod volume</a>
      <ul>
        <li><a href="#question-5">Question</a></li>
        <li><a href="#ref">Ref</a></li>
        <li><a href="#answer-5">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-7--node-and-pod-resource-usage">Question 7 | Node and Pod Resource Usage</a>
      <ul>
        <li><a href="#question-6">Question</a></li>
        <li><a href="#my-answer-5">My Answer</a></li>
        <li><a href="#answer-6">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-8--get-controlplane-information">Question 8 | Get Controlplane Information</a>
      <ul>
        <li><a href="#question-7">Question</a></li>
        <li><a href="#my-answer-6">My Answer</a></li>
        <li><a href="#answer-7">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-9--kill-scheduler-manual-scheduling">Question 9 | Kill Scheduler, Manual Scheduling</a>
      <ul>
        <li><a href="#question-8">Question</a></li>
        <li><a href="#my-answer-7">My Answer</a></li>
        <li><a href="#answer-8">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-10--rbac-serviceaccount-role-rolebinding">Question 10 | RBAC ServiceAccount Role RoleBinding</a>
      <ul>
        <li><a href="#question-9">Question</a></li>
        <li><a href="#my-answer-8">My Answer</a></li>
        <li><a href="#answer-9">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-11--daemonset-on-all-nodes">Question 11 | DaemonSet on all Nodes</a>
      <ul>
        <li><a href="#question-10">Question</a></li>
        <li><a href="#ref-1">Ref</a></li>
        <li><a href="#answer-10">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-12--deployment-on-all-nodes">Question 12 | Deployment on all Nodes</a>
      <ul>
        <li><a href="#question-11">Question</a></li>
        <li><a href="#ref-2">Ref</a></li>
        <li><a href="#answer-11">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-13--multi-containers-and-pod-shared-volume">Question 13 | Multi Containers and Pod shared Volume</a>
      <ul>
        <li><a href="#question-12">Question</a></li>
        <li><a href="#my-answer-9">My Answer</a></li>
        <li><a href="#answer-12">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-14--find-out-cluster-information">Question 14 | Find out Cluster Information</a>
      <ul>
        <li><a href="#question-13">Question</a></li>
        <li><a href="#answer-13">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-15--cluster-event-logging">Question 15 | Cluster Event Logging</a>
      <ul>
        <li><a href="#question-14">Question</a></li>
        <li><a href="#my-answer-10">My Answer</a></li>
        <li><a href="#answer-14">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-16--namespaces-and-api-resources">Question 16 | Namespaces and Api Resources</a>
      <ul>
        <li><a href="#question-15">Question</a></li>
        <li><a href="#my-answer-11">My Answer</a></li>
        <li><a href="#answer-15">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-17--find-container-of-pod-and-check-info">Question 17 | Find Container of Pod and check info</a>
      <ul>
        <li><a href="#question-16">Question</a></li>
        <li><a href="#my-answer-12">My Answer</a></li>
        <li><a href="#answer-16">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-18--fix-kubelet">Question 18 | Fix Kubelet</a>
      <ul>
        <li><a href="#question-17">Question</a></li>
        <li><a href="#answer-17">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-19--create-secret-and-mount-into-pod">Question 19 | Create Secret and mount into Pod</a>
      <ul>
        <li><a href="#question-18">Question</a></li>
        <li><a href="#ref-3">Ref</a></li>
        <li><a href="#answer-18">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-20--update-kubernetes-version-and-join-cluster">Question 20 | Update Kubernetes Version and join cluster</a>
      <ul>
        <li><a href="#question-19">Question</a></li>
        <li><a href="#ref-4">Ref</a></li>
        <li><a href="#answer-19">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-21--create-a-static-pod-and-service">Question 21 | Create a Static Pod and Service</a>
      <ul>
        <li><a href="#question-20">Question</a></li>
        <li><a href="#ref-5">Ref</a></li>
        <li><a href="#answer-20">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-22--check-how-long-certificates-are-valid">Question 22 | Check how long certificates are valid</a>
      <ul>
        <li><a href="#question-21">Question</a></li>
        <li><a href="#answer-21">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-23--kubelet-clientserver-cert-info">Question 23 | Kubelet client/server cert info</a>
      <ul>
        <li><a href="#question-22">Question</a></li>
        <li><a href="#answer-22">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-24--networkpolicy">Question 24 | NetworkPolicy</a>
      <ul>
        <li><a href="#question-23">Question</a></li>
        <li><a href="#ref-6">Ref</a></li>
        <li><a href="#answer-23">Answer</a></li>
      </ul>
    </li>
    <li><a href="#question-25--etcd-snapshot-save-and-restore">Question 25 | Etcd Snapshot Save and Restore</a>
      <ul>
        <li><a href="#question-24">Question</a></li>
        <li><a href="#ref-7">Ref</a></li>
        <li><a href="#answer-24">Answer</a></li>
      </ul>
    </li>
    <li><a href="#extra-question-1--find-pods-first-to-be-terminated">Extra Question 1 | Find Pods first to be terminated</a>
      <ul>
        <li><a href="#question-25">Question</a></li>
        <li><a href="#answer-25">Answer</a></li>
      </ul>
    </li>
    <li><a href="#extra-question-2--curl-manually-contact-api">Extra Question 2 | Curl Manually Contact API</a>
      <ul>
        <li><a href="#question-26">Question</a></li>
        <li><a href="#answer-26">Answer</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#preview-question-1">Preview Question 1</a>
      <ul>
        <li><a href="#question-27">Question</a></li>
        <li><a href="#answer-27">Answer</a></li>
      </ul>
    </li>
    <li><a href="#preview-question-2">Preview Question 2</a>
      <ul>
        <li><a href="#question-28">Question</a></li>
        <li><a href="#answer-28">Answer</a></li>
      </ul>
    </li>
    <li><a href="#preview-question-3">Preview Question 3</a>
      <ul>
        <li><a href="#question-29">Question</a></li>
        <li><a href="#answer-29">Answer</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#knowledge">Knowledge</a></li>
    <li><a href="#cka-preparation">CKA Preparation</a></li>
    <li><a href="#kubernetes-documentation">Kubernetes Documentation</a></li>
    <li><a href="#the-test-environment--browser-terminal">The Test Environment / Browser Terminal</a></li>
    <li><a href="#psi-bridge">PSI Bridge</a></li>
    <li><a href="#browser-terminal-setup">Browser Terminal Setup</a>
      <ul>
        <li></li>
        <li><a href="#be-fast">Be fast</a></li>
        <li><a href="#vim">Vim</a></li>
        <li><a href="#split-terminal-screen">Split terminal screen</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  
  
    <a href="https://github.com/zyt153" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://www.douban.com/people/167005886/?_i=4097828i6Qoeme" rel="me noopener" class="iconfont"
      title="douban"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M926.917973 37.80608C959.65184 37.80608 986.19392 64.34816 986.19392 97.082027L986.19392 926.917973C986.19392 959.65184 959.65184 986.19392 926.917973 986.19392L97.082027 986.19392C64.34816 986.19392 37.80608 959.65184 37.80608 926.917973L37.80608 97.082027C37.80608 64.34816 64.34816 37.80608 97.082027 37.80608zM176.653653 176.19968 176.653653 252.678827 825.658027 252.678827 825.658027 176.19968zM217.719467 316.146347 217.719467 628.08064 273.524053 628.08064 341.292373 770.39616 157.259093 770.39616 157.259093 845.417813 842.949973 845.417813 842.949973 770.39616 654.226773 770.39616 722.899627 628.08064 783.67744 628.08064 783.67744 316.146347zM684.885333 392.891733 684.885333 553.987413 312.576 553.987413 312.576 392.891733zM570.770773 770.39616 426.653013 770.39616 359.621973 628.08064 639.443627 628.08064z"></path>
</svg>

    </a>
  
    <a href="https://space.bilibili.com/35945316?spm_id_from=333.1007.0.0" rel="me noopener" class="iconfont"
      title="bilibili"  target="_blank"
      >
      <svg
  class="icon" style="" viewBox="0 0 1024 1024" version="1.1" width="36"
  height="36" id="svg8">
  <path
      style=""
      d="M 744.60599,0.00486267 A 41.779915,41.779915 0 0 0 710.4184,18.673394 L 548.5048,255.32642 h -11.70046 a 41.779915,41.779915 0 0 0 -10.80295,-7.84928 L 235.66,97.084498 a 41.779915,41.779915 0 0 0 -20.07193,-4.960864 41.779915,41.779915 0 0 0 -18.3748,79.145436 L 359.4859,255.32642 H 128.16909 c -49.458302,0 -89.27932,39.82105 -89.27932,89.27932 v 508.65224 c 0,49.4583 39.821018,89.27934 89.27932,89.27934 h 19.48445 C 149.12802,984.5043 179.92773,1024 224.79179,1024 c 44.86407,0 75.66379,-39.4957 77.13826,-81.46268 H 719.98116 C 721.45559,984.5043 752.25533,1024 797.1194,1024 c 44.86406,0 75.6638,-39.4957 77.13824,-81.46268 h 21.57323 c 49.45831,0 89.27936,-39.82104 89.27936,-89.27934 V 344.60574 c 0,-49.45827 -39.82105,-89.27932 -89.27936,-89.27932 H 649.74567 L 779.38103,65.866924 A 41.779915,41.779915 0 0 0 744.60599,0.00486267 Z M 644.49108,418.70871 c 6.29985,0.21538 12.44451,2.01107 17.86888,5.22196 l 171.36218,98.10771 c 18.23417,10.21935 24.63334,33.34627 14.24614,51.48533 -10.38726,18.13909 -33.57344,24.32718 -51.61587,13.77296 L 624.9903,489.18895 c -15.21356,-8.41858 -22.66871,-26.1765 -18.03211,-42.93436 4.63664,-16.75784 20.15573,-28.14465 37.53289,-27.54588 z M 350.2006,432.31846 c 16.89952,0.0317 31.69582,11.33328 36.17844,27.62747 4.48262,16.2942 -2.44981,33.57765 -16.95507,42.24898 l -140.7157,86.91312 c -17.68528,11.18244 -41.09629,5.77692 -52.08912,-12.02686 -10.99282,-17.80373 -5.33855,-41.15658 12.58167,-51.95857 L 329.9002,438.2095 c 6.0643,-3.86439 13.10951,-5.90891 20.3004,-5.89104 z M 501.605,641.53985 c 3.75002,-0.15248 7.48645,0.53903 10.93349,2.0235 0.15842,0.0637 0.31618,0.12888 0.47325,0.19582 0.59328,0.27092 1.17574,0.56489 1.74609,0.88121 0.15868,0.0854 0.31643,0.17233 0.47325,0.2611 0.55694,0.32165 1.10131,0.66458 1.63185,1.02807 0.16455,0.1123 0.32777,0.2265 0.48956,0.34269 0.50382,0.36781 0.99371,0.75428 1.46868,1.15864 0.18724,0.15504 0.37218,0.31282 0.55484,0.47323 0.43271,0.38784 0.8518,0.79061 1.25653,1.20756 0.15449,0.16114 0.30679,0.32437 0.45693,0.48959 0.40798,0.44266 0.79989,0.89988 1.17494,1.37076 0.17799,0.22544 0.35205,0.45395 0.5222,0.68538 0.25932,0.34701 0.50964,0.70071 0.75064,1.06071 0.26712,0.39516 0.52286,0.79784 0.76699,1.20757 0.16907,0.29043 0.33231,0.58424 0.48957,0.88123 0.21836,0.41297 0.42513,0.83199 0.62009,1.25653 0.14836,0.32333 0.28983,0.64976 0.42429,0.97911 0.21319,0.51552 0.40915,1.03801 0.58747,1.5666 0.0677,0.19499 0.13296,0.39085 0.19582,0.58748 0.18652,0.60823 0.34984,1.22334 0.48957,1.84399 0.0397,0.16277 0.0779,0.32601 0.11423,0.48957 0.1436,0.69112 0.25788,1.38801 0.34269,2.08877 0.005,0.0381 0.0111,0.0761 0.0163,0.11424 0.0857,0.78056 0.13474,1.56471 0.14687,2.34988 0.005,0.0543 0.0111,0.10879 0.0163,0.1632 0,0 -0.008,1.12132 0,1.45234 0,0 -0.14697,17.84761 5.89102,34.12231 3.01902,8.13734 7.33278,15.10615 12.61433,19.61501 5.28157,4.50889 11.42894,7.62081 23.64572,7.62081 12.2168,0 18.36416,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.5953,-11.47767 12.6143,-19.61501 6.03799,-16.2747 5.89103,-34.12231 5.89103,-34.12231 -0.44885,-13.87045 10.45922,-25.46302 24.3311,-25.86506 13.87189,-0.40201 25.42828,10.53953 25.78348,24.41272 0,0 1.11929,25.7226 -9.00791,53.01927 -5.06359,13.64832 -13.1986,28.46036 -27.05631,40.29073 -13.85772,11.83039 -33.5454,19.63135 -56.20142,19.63135 -22.65603,0 -42.34371,-7.80096 -56.20141,-19.63135 -4.1801,-3.56856 -7.78733,-7.42433 -10.99878,-11.42303 -3.21235,4.00037 -6.81703,7.85309 -10.99876,11.42303 -13.85773,11.83039 -33.5454,19.63135 -56.20144,19.63135 -22.65601,0 -42.3437,-7.80096 -56.2014,-19.63135 -13.85775,-11.83037 -21.99272,-26.64241 -27.05632,-40.29073 -10.12725,-27.29667 -9.00789,-53.01928 -9.00789,-53.01927 0.20714,-13.83687 11.58744,-24.88848 25.42444,-24.69013 14.1263,0.19991 25.2971,12.0278 24.69011,26.14247 0,0 -0.14697,17.84761 5.89103,34.12231 3.01902,8.13734 7.31646,15.10615 12.598,19.61501 5.28155,4.50889 11.44526,7.62081 23.66203,7.62081 12.21681,0 18.36418,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.57899,-11.47767 12.598,-19.61501 5.76352,-15.53489 5.89112,-32.05691 5.89103,-33.56746 0.006,-0.37466 0.0111,-1.05336 0.0163,-1.20759 -0.0117,-0.74583 0.0105,-1.49177 0.0652,-2.23565 0.009,-0.15784 0.0204,-0.31561 0.0327,-0.47324 0.14204,-1.56859 0.43163,-3.12027 0.86487,-4.63449 0.0213,-0.0763 0.0433,-0.15244 0.0652,-0.22848 3.0335,-10.25748 12.24157,-17.46007 22.92769,-17.93417 z"
      id="rect824"/>
</svg>

    </a>


<a href="https://zyt153.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
  
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2023 -
    2024
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        大白猫
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.2fa20daa982115b9f2c34b25443e21b017260661e7b5017e1bf5e91ae66e1c0a.js" integrity="sha256-L6INqpghFbnyw0slRD4hsBcmBmHntQF&#43;G/XpGuZuHAo=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  

















  </body>
</html>
